{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class term():\n",
    "    joint_ids = ['FL_hip_joint', 'FR_hip_joint', 'RL_hip_joint', 'RR_hip_joint', 'FL_thigh_joint', 'FR_thigh_joint', 'RL_thigh_joint', 'RR_thigh_joint', 'FL_calf_joint', 'FR_calf_joint', 'RL_calf_joint', 'RR_calf_joint']#['RR_hip', 'RR_joint', 'RR_calf']\n",
    "    num_envs = 64\n",
    "    _num_legs = 4\n",
    "    _prevision_horizon = 10\n",
    "\n",
    "    def __init__(self):\n",
    "        self._num_joints = len(self.joint_ids)\n",
    "        self.f = torch.zeros(self.num_envs, self._num_legs)\n",
    "        self.d = torch.zeros(self.num_envs, self._num_legs)\n",
    "        self.p = torch.zeros(self.num_envs, self._num_legs, self._prevision_horizon)\n",
    "        self.F = torch.zeros(self.num_envs, self._num_legs, self._prevision_horizon)\n",
    "        self.z = [self.f, self.d, self.p, self.F]\n",
    "\n",
    "        # create tensors for raw and processed actions\n",
    "        self._raw_actions = torch.zeros(self.num_envs, self.action_dim2)\n",
    "        self._processed_actions = torch.zeros_like(self.raw_actions)\n",
    "\n",
    "    @property\n",
    "    def action_dim(self) -> int:\n",
    "        return self._num_joints\n",
    "    \n",
    "    @property\n",
    "    def action_dim2(self) -> int:\n",
    "        return self.f.shape[1:].numel() + self.d.shape[1:].numel() + self.p.shape[1:].numel() + self.F.shape[1:].numel()\n",
    "    \n",
    "    @property\n",
    "    def action_dim3(self) -> int:\n",
    "        return sum(variable.shape[1:].numel() for variable in self.z)\n",
    "    \n",
    "    @property\n",
    "    def raw_actions(self) -> torch.Tensor:\n",
    "        return self._raw_actions\n",
    "\n",
    "    @property\n",
    "    def processed_actions(self) -> torch.Tensor:\n",
    "        return self._processed_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "term1 = term()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term1.action_dim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term1.action_dim3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 88])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term1.raw_actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term1.z[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term1.num_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor : tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         ...,\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         ...,\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         ...,\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         ...,\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         ...,\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         ...,\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "shape : 24\n",
      "torch.Size([1536])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(term1.num_envs, term1.action_dim,2)\n",
    "print('tensor :',a)\n",
    "print('shape :', a.shape[1:].numel())\n",
    "\n",
    "print(a.flatten().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'omni.physics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momni\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01misaac\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morbit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AssetBase\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momni\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01misaac\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morbit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marticulation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Articulation\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momni\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01misaac\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morbit_tasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlocomotion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_based\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_based_env_cfg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocomotionModelBasedEnvCfg\n",
      "File \u001b[0;32m~/Documents/dls_orbit_bat_private/source/extensions/omni.isaac.orbit/omni/isaac/orbit/assets/__init__.py:41\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2022-2024, The ORBIT Project Developers.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"Sub-package for different assets, such as rigid objects and articulations.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mAn asset is a physical object that can be spawned in the simulation. The class handles both\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03mthe corresponding actuator torques.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marticulation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Articulation, ArticulationCfg, ArticulationData\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masset_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AssetBase\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masset_base_cfg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AssetBaseCfg\n",
      "File \u001b[0;32m~/Documents/dls_orbit_bat_private/source/extensions/omni.isaac.orbit/omni/isaac/orbit/assets/articulation/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2022-2024, The ORBIT Project Developers.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"Sub-module for rigid articulated assets.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marticulation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Articulation\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marticulation_cfg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArticulationCfg\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marticulation_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArticulationData\n",
      "File \u001b[0;32m~/Documents/dls_orbit_bat_private/source/extensions/omni.isaac.orbit/omni/isaac/orbit/assets/articulation/articulation.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcarb\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01momni\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mphysics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mphysx\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momni\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01misaac\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArticulationActions\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpxr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UsdPhysics\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'omni.physics'"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from omni.isaac.orbit.assets import AssetBase\n",
    "from omni.isaac.orbit.assets.articulation import Articulation\n",
    "from omni.isaac.orbit_tasks.locomotion.model_based.model_based_env_cfg import LocomotionModelBasedEnvCfg\n",
    "from omni.isaac.orbit_tasks.locomotion.model_based.config.unitree_aliengo.aliengo_base_env_cfg import UnitreeAliengoBaseEnvCfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "seed = 42\n",
    "key = jax.random.key(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available devices: 1\n",
      "current device: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'available devices: {torch.cuda.device_count()}')\n",
    "print(f'current device: { torch.cuda.current_device()}')\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape :  torch.Size([64, 12])\n",
      "device :  cuda:0\n"
     ]
    }
   ],
   "source": [
    "output_torques = (torch.rand(term1.num_envs, term1._num_joints, device='cuda') * 80) - 40\n",
    "print('shape : ',output_torques.shape)\n",
    "print('device : ',output_torques.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_torques_jax = jax.random.normal(key=key, shape=output_torques.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Torch ---\n",
      "Shape :  torch.Size([64, 12])\n",
      "Type :  torch.FloatTensor\n",
      "Type :  <class 'torch.Tensor'>\n",
      "\n",
      "--- Jax ---\n",
      "Shape :  (64, 12)\n",
      "Type :  <class 'jaxlib.xla_extension.ArrayImpl'>\n"
     ]
    }
   ],
   "source": [
    "print('--- Torch ---')\n",
    "print('Shape : ', output_torques.shape)\n",
    "print('Type : ', output_torques.type())\n",
    "print('Type : ', type(output_torques))\n",
    "\n",
    "print('')\n",
    "print('--- Jax ---')\n",
    "print('Shape : ', output_torques_jax.shape)\n",
    "print('Type : ', type(output_torques_jax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1.0063325, dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_torques_jax.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.dlpack\n",
    "import torch\n",
    "import torch.utils.dlpack\n",
    "\n",
    "def jax_to_torch(x):\n",
    "    return torch.utils.dlpack.from_dlpack(jax.dlpack.to_dlpack(x))\n",
    "def torch_to_jax(x):\n",
    "    return jax.dlpack.from_dlpack(torch.utils.dlpack.to_dlpack(x))\n",
    "\n",
    "a = torch.tensor([1,2,3]).cuda()\n",
    "a_jax = torch_to_jax(a)\n",
    "print(a_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{cuda(id=0)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape :  torch.Size([64, 12])\n",
      "device :  cuda:0\n",
      "Type :  <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "output_torques = (torch.rand(term1.num_envs, term1._num_joints, device='cuda') * 80) - 40\n",
    "print('shape : ',output_torques.shape)\n",
    "print('device : ',output_torques.device)\n",
    "print('Type : ', type(output_torques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape :  (64, 12)\n",
      "device :  {cuda(id=0)}\n",
      "Type :  <class 'jaxlib.xla_extension.ArrayImpl'>\n"
     ]
    }
   ],
   "source": [
    "output_torques_jax = torch_to_jax(output_torques)\n",
    "print('Shape : ', output_torques_jax.shape)\n",
    "print('device : ',output_torques_jax.devices())\n",
    "print('Type : ', type(output_torques_jax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alo() -> tuple[int, int, str]:\n",
    "    a = 2\n",
    "    b = 3\n",
    "    c = 4\n",
    "    return a, b, str(c)\n",
    "\n",
    "def alo2():\n",
    "    a = 2\n",
    "    b = 3\n",
    "    c = 4\n",
    "    return a, b, str(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, '4')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, '4')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alo2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(alo()))\n",
    "print(type(alo2()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tuple[2,3,4]\n",
    "alo()\n",
    "\n",
    "d, f, e = alo()\n",
    "type(alo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.bool\n",
      "tensor([[0.5317, 0.4781, 0.3271],\n",
      "        [0.3938, 0.3433, 0.9002]])\n",
      "tensor([[ True, False,  True],\n",
      "        [False,  True, False]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5317, 0.0000, 0.3271],\n",
       "        [0.0000, 0.3433, 0.0000]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([0, 1.21, 2])\n",
    "b = torch.tensor([True, True, False])\n",
    "\n",
    "shape = [2,3]\n",
    "a = torch.rand(shape)\n",
    "b = torch.empty(shape, dtype=torch.bool).bernoulli(0.5)\n",
    "\n",
    "\n",
    "print(a.dtype)\n",
    "print(b.dtype)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[5, 4, 3]' is invalid for input of size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m number_of_joint_per_leg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Modify the tensor to shape (batch_size, num_legs, number_of_joint_per_leg)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m modified_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_joint_per_leg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Check the shape of the modified tensor\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModified tensor shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, modified_tensor\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[5, 4, 3]' is invalid for input of size 20"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming you have a tensor of shape (batch_size, num_legs)\n",
    "tensor = torch.randn(5, 4)  # Example tensor with shape (5, 4)\n",
    "\n",
    "# Define the number of joints per leg\n",
    "number_of_joint_per_leg = 3\n",
    "\n",
    "# Modify the tensor to shape (batch_size, num_legs, number_of_joint_per_leg)\n",
    "modified_tensor = torch.reshape(tensor, (tensor.shape[0], tensor.shape[1], number_of_joint_per_leg))\n",
    "\n",
    "# Check the shape of the modified tensor\n",
    "print(\"Modified tensor shape:\", modified_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00016944000124931335 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Create some tensors for demonstration\n",
    "T_shape = [4096,4,3]\n",
    "c_shape = [4096,4]\n",
    "T_1 = torch.rand(T_shape).cuda()\n",
    "T_2 = torch.rand(T_shape).cuda()\n",
    "c = torch.empty(c_shape, dtype=torch.bool).bernoulli(0.5).cuda()\n",
    "\n",
    "\n",
    "# Create CUDA events\n",
    "start_event = torch.cuda.Event(enable_timing=True)\n",
    "end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "# Record start event\n",
    "start_event.record()\n",
    "\n",
    "# Example operation (e.g., matrix multiplication)\n",
    "\n",
    "result = (T_1 * c.unsqueeze(-1)) + (T_2 * (~c).unsqueeze(-1))\n",
    "\n",
    "# Record end event\n",
    "end_event.record()\n",
    "\n",
    "# Wait for computations to finish\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = start_event.elapsed_time(end_event) / 1000  # Convert to seconds\n",
    "print(\"Time taken:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "def custom_operation(T_1, T_2, c_star):\n",
    "    # Element-wise multiplication with c_star and its complement\n",
    "    term1 = T_1 * c_star[..., None]\n",
    "    term2 = T_2 * (~c_star)[..., None]\n",
    "    \n",
    "    # Sum the terms along the joint dimension\n",
    "    T = term1 + term2\n",
    "    \n",
    "    return T\n",
    "\n",
    "# Example usage\n",
    "batch_size = 3\n",
    "num_legs = 4\n",
    "num_of_joints_per_leg = 5\n",
    "\n",
    "# Random tensors for T_1, T_2, and c_star\n",
    "T_1 = jax.random.normal(jax.random.PRNGKey(0), (batch_size, num_legs, num_of_joints_per_leg))\n",
    "T_2 = jax.random.normal(jax.random.PRNGKey(1), (batch_size, num_legs, num_of_joints_per_leg))\n",
    "c_star = jax.random.randint(jax.random.PRNGKey(2), (batch_size, num_legs), 0, 2)\n",
    "\n",
    "# Perform custom operation\n",
    "T = custom_operation(T_1, T_2, c_star)\n",
    "\n",
    "print(T.shape)  # Output shape should be (batch_size, num_legs, num_of_joints_per_leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "\n",
    "@jit\n",
    "def custom_operation(T_1, T_2, c_star):\n",
    "    # Element-wise multiplication with c_star and its complement\n",
    "    term1 = T_1 * c_star[..., None]\n",
    "    term2 = T_2 * (~c_star)[..., None]\n",
    "    \n",
    "    # Sum the terms along the joint dimension\n",
    "    T = term1 + term2\n",
    "    \n",
    "    return T\n",
    "\n",
    "# Example usage\n",
    "batch_size = 3\n",
    "num_legs = 4\n",
    "num_of_joints_per_leg = 5\n",
    "\n",
    "# Random tensors for T_1, T_2, and c_star\n",
    "T_1 = jax.random.normal(jax.random.PRNGKey(0), (batch_size, num_legs, num_of_joints_per_leg))\n",
    "T_2 = jax.random.normal(jax.random.PRNGKey(1), (batch_size, num_legs, num_of_joints_per_leg))\n",
    "c_star = jax.random.randint(jax.random.PRNGKey(2), (batch_size, num_legs), 0, 2)\n",
    "\n",
    "# Move tensors to GPU\n",
    "T_1 = jax.device_put(T_1, jax.devices('gpu')[0])\n",
    "T_2 = jax.device_put(T_2, jax.devices('gpu')[0])\n",
    "c_star = jax.device_put(c_star, jax.devices('gpu')[0])\n",
    "\n",
    "# Perform custom operation\n",
    "T = custom_operation(T_1, T_2, c_star)\n",
    "\n",
    "print(T.shape)  # Output shape should be (batch_size, num_legs, num_of_joints_per_leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00010966400057077407 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create some tensors for demonstration\n",
    "batch_size = 4096\n",
    "num_legs = 4\n",
    "num_of_joints_per_leg = 3\n",
    "T_1 = jax.random.normal(jax.random.PRNGKey(0), (batch_size, num_legs, num_of_joints_per_leg))\n",
    "T_2 = jax.random.normal(jax.random.PRNGKey(1), (batch_size, num_legs, num_of_joints_per_leg))\n",
    "c_star = jax.random.randint(jax.random.PRNGKey(2), (batch_size, num_legs), 0, 2)\n",
    "\n",
    "# Create CUDA events\n",
    "start_event = torch.cuda.Event(enable_timing=True)\n",
    "end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "# Record start event\n",
    "start_event.record()\n",
    "\n",
    "# Example operation (e.g., matrix multiplication)\n",
    "T = custom_operation(T_1, T_2, c_star)\n",
    "\n",
    "# result = (T_1 * c.unsqueeze(-1)) + (T_2 * (~c).unsqueeze(-1))\n",
    "\n",
    "# Record end event\n",
    "end_event.record()\n",
    "\n",
    "# Wait for computations to finish\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = start_event.elapsed_time(end_event) / 1000  # Convert to seconds\n",
    "print(\"Time taken:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "num_legs = 4\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "[4, 5, 6, 7]\n",
      "[8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "print(a[:num_legs])\n",
    "print(a[num_legs:2*num_legs])\n",
    "print(a[2*num_legs:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gait Generator\n",
    "from : f, d, phase, time_horizon  \n",
    "return : c, new_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Args:\n",
    "            - f   (torch.Tensor): Leg frequency                         of shape(batch_size, num_legs, parallel_rollout)\n",
    "            - d   (torch.Tensor): Stepping duty cycle                   of shape(batch_size, num_legs, parallel_rollout)\n",
    "            - phase (tch.Tensor): phase of leg                          of shape(batch_size, num_legs, parallel_rollout)\n",
    "            - time_horizon (int): Time horizon for the contact sequence\n",
    "\n",
    "        Returns:\n",
    "            - c     (torch.bool): Foot contact sequence                 of shape(batch_size, num_legs, time_horizon, parallel_rollout)\n",
    "            - phase (tch.Tensor): The phase updated by one time steps   of shape(batch_size, num_legs, parallel_rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Leg Frequency : f ----\n",
      "f shape: torch.Size([1, 2, 3])\n",
      "f : tensor([[[1., 2., 3.],\n",
      "         [1., 2., 3.]]])\n",
      "\n",
      "---- Stepping duty cycle : d ----\n",
      "d shape: torch.Size([1, 2, 3])\n",
      "d : tensor([[[2., 2., 2.],\n",
      "         [2., 2., 2.]]])\n",
      "\n",
      "---- Phase ----\n",
      "phase shape: torch.Size([1, 2, 3])\n",
      "phase : tensor([[[1., 2., 3.],\n",
      "         [1., 2., 3.]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_envs = 1\n",
    "_num_legs = 2\n",
    "parallel_rollout = 3\n",
    "device = 'cpu'\n",
    "\n",
    "time_horizon = 4\n",
    "dt = 0.1\n",
    "\n",
    "f = torch.zeros(num_envs, _num_legs, parallel_rollout, device=device)\n",
    "f = torch.Tensor([1,2,3]).expand(num_envs,_num_legs, parallel_rollout)\n",
    "print('---- Leg Frequency : f ----')\n",
    "print('f shape:', f.shape)\n",
    "print('f :', f)\n",
    "print()\n",
    "\n",
    "d = torch.zeros(num_envs, _num_legs, parallel_rollout, device=device)\n",
    "d = d+2\n",
    "print('---- Stepping duty cycle : d ----')\n",
    "print('d shape:', d.shape)\n",
    "print('d :', d)\n",
    "print()\n",
    "\n",
    "phase = torch.zeros(num_envs, _num_legs, parallel_rollout, device=device)\n",
    "phase = torch.Tensor([1,2,3]).expand(num_envs,_num_legs, parallel_rollout)\n",
    "print('---- Phase ----')\n",
    "print('phase shape:', phase.shape)\n",
    "print('phase :', phase)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000, 0.4000])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(start=1, end=time_horizon, steps=time_horizon)*dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3])\n",
      "torch.Size([1, 2, 3, 1])\n",
      "torch.Size([1, 2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1., 1.],\n",
       "          [2., 2., 2., 2.],\n",
       "          [3., 3., 3., 3.]],\n",
       "\n",
       "         [[1., 1., 1., 1.],\n",
       "          [2., 2., 2., 2.],\n",
       "          [3., 3., 3., 3.]]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(phase.shape)\n",
    "print(phase.unsqueeze(-1).shape)\n",
    "print(phase.unsqueeze(-1).expand(*[-1] * len(phase.shape),time_horizon).shape)\n",
    "phase.unsqueeze(-1).expand(num_envs,_num_legs,parallel_rollout,time_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.1000, 1.2000, 1.3000, 1.4000],\n",
       "          [2.2000, 2.4000, 2.6000, 2.8000],\n",
       "          [3.3000, 3.6000, 3.9000, 4.2000]],\n",
       "\n",
       "         [[1.1000, 1.2000, 1.3000, 1.4000],\n",
       "          [2.2000, 2.4000, 2.6000, 2.8000],\n",
       "          [3.3000, 3.6000, 3.9000, 4.2000]]]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_phases = phase.unsqueeze(-1).expand(num_envs,_num_legs,parallel_rollout,time_horizon) + f.unsqueeze(-1).expand(num_envs,_num_legs,parallel_rollout,time_horizon)*torch.linspace(start=1, end=time_horizon, steps=time_horizon)*dt\n",
    "\n",
    "print(new_phases.shape)\n",
    "new_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1000, 0.2000, 0.3000, 0.4000],\n",
       "          [0.2000, 0.4000, 0.6000, 0.8000],\n",
       "          [0.3000, 0.6000, 0.9000, 0.2000]],\n",
       "\n",
       "         [[0.1000, 0.2000, 0.3000, 0.4000],\n",
       "          [0.2000, 0.4000, 0.6000, 0.8000],\n",
       "          [0.3000, 0.6000, 0.9000, 0.2000]]]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_phases = new_phases%1\n",
    "\n",
    "print(new_phases.shape)\n",
    "new_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1000, 0.2000, 0.3000],\n",
       "         [0.1000, 0.2000, 0.3000]]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_phase = new_phases[...,0]\n",
    "\n",
    "print(new_phase.shape)\n",
    "new_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = new_phases > d.unsqueeze(-1).expand(*[-1] * len(d.shape),time_horizon)\n",
    "\n",
    "print(c.shape)\n",
    "c.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gait_generator(f, d, phase, time_horizon):\n",
    "    new_phases = phase.unsqueeze(-1).expand(*[-1] * len(phase.shape),time_horizon) + f.unsqueeze(-1).expand(*[-1] * len(f.shape),time_horizon)*torch.linspace(start=1, end=time_horizon, steps=time_horizon)*dt\n",
    "\n",
    "    new_phases = new_phases%1\n",
    "\n",
    "    new_phase = new_phases[..., 0]\n",
    "\n",
    "    c = new_phases > d.unsqueeze(-1).expand(*[-1] * len(d.shape),time_horizon)\n",
    "\n",
    "    return c, new_phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([1, 2, 1, 3, 1])\n",
      "Tensor shape after squeezing: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor (size can be unknown)\n",
    "tensor = torch.randn(1, 2, 1, 3, 1)\n",
    "\n",
    "# Squeeze out singleton dimensions\n",
    "unsqueezed_tensor = tensor.squeeze()\n",
    "\n",
    "print(\"Original tensor shape:\", tensor.shape)\n",
    "print(\"Tensor shape after squeezing:\", unsqueezed_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saved Hsitory of Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # # parse the body index\n",
    "        # body_ids, body_names = self._asset.find_bodies(self.cfg.body_name)\n",
    "        # if len(body_ids) != 1:\n",
    "        #     raise ValueError(\n",
    "        #         f\"Expected one match for the body name: {self.cfg.body_name}. Found {len(body_ids)}: {body_names}.\"\n",
    "        #     )\n",
    "        # # save only the first body index\n",
    "        # self._body_idx = body_ids[0]\n",
    "        # self._body_name = body_names[0]\n",
    "        # # check if articulation is fixed-base\n",
    "        # # if fixed-base then the jacobian for the base is not computed\n",
    "        # # this means that number of bodies is one less than the articulation's number of bodies\n",
    "        # if self._asset.is_fixed_base:\n",
    "        #     self._jacobi_body_idx = self._body_idx - 1\n",
    "        # else:\n",
    "        #     self._jacobi_body_idx = self._body_idx\n",
    "        # carb.log_info(  # log info for debugging\n",
    "        #     f\"Resolved body name for the action term {self.__class__.__name__}: {self._body_name} [{self._body_idx}]\"\n",
    "        # )\n",
    "\n",
    "        # # convert the fixed offsets to torch tensors of batched shape\n",
    "        # if self.cfg.body_offset is not None:\n",
    "        #     self._offset_pos = torch.tensor(self.cfg.body_offset.pos, device=self.device).repeat(self.num_envs, 1)\n",
    "        #     self._offset_rot = torch.tensor(self.cfg.body_offset.rot, device=self.device).repeat(self.num_envs, 1)\n",
    "        # else:\n",
    "        #     self._offset_pos, self._offset_rot = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Stolen from DifferentialInverseKinematicsAction\n",
    "    def _compute_frame_jacobian(self):\n",
    "        \"\"\"Computes the geometric Jacobian of the target frame in the root frame.\n",
    "\n",
    "        This function accounts for the target frame offset and applies the necessary transformations to obtain\n",
    "        the right Jacobian from the parent body Jacobian.\n",
    "        \"\"\"\n",
    "        # read the parent jacobian\n",
    "        jacobian = self._asset.root_physx_view.get_jacobians()[:, self._jacobi_body_idx, :, self._joint_ids]\n",
    "\n",
    "        jacobian = self._asset.root_physx_view.get_jacobians()\n",
    "\n",
    "        \"\"\"Ordered names of bodies in articulation (through rigid body view).\"\"\"\n",
    "        prim_paths = self._asset.body_physx_view.prim_paths[: self._asset.num_bodies]\n",
    "        body_names = [path.split(\"/\")[-1] for path in prim_paths]\n",
    "        print(\"Link names through body view: \", body_names) #['base', 'FL_hip', 'FL_thigh', 'FL_calf', 'FL_foot', 'FR_hip', 'FR_thigh', 'FR_calf', 'FR_foot', 'RL_hip', 'RL_thigh', 'RL_calf', 'RL_foot', 'RR_hip', 'RR_thigh', 'RR_calf', 'RR_foot']\n",
    "\n",
    "        \"\"\"Ordered names of bodies in articulation (through articulation view).\"\"\"\n",
    "        body_names = self._asset.root_physx_view.shared_metatype.link_names\n",
    "        print(\"Link names through articulation view: \", body_names) #['base', 'FL_hip', 'FR_hip', 'RL_hip', 'RR_hip', 'FL_thigh', 'FR_thigh', 'RL_thigh', 'RR_thigh', 'FL_calf', 'FR_calf', 'RL_calf', 'RR_calf', 'FL_foot', 'FR_foot', 'RL_foot', 'RR_foot']\n",
    "\n",
    "        # account for the offset\n",
    "        if self.cfg.body_offset is not None:\n",
    "            # Modify the jacobian to account for the offset\n",
    "            # -- translational part\n",
    "            # v_link = v_ee + w_ee x r_link_ee = v_J_ee * q + w_J_ee * q x r_link_ee\n",
    "            #        = (v_J_ee + w_J_ee x r_link_ee ) * q\n",
    "            #        = (v_J_ee - r_link_ee_[x] @ w_J_ee) * q\n",
    "            jacobian[:, 0:3, :] += torch.bmm(-math_utils.skew_symmetric_matrix(self._offset_pos), jacobian[:, 3:, :])\n",
    "            # -- rotational part\n",
    "            # w_link = R_link_ee @ w_ee\n",
    "            jacobian[:, 3:, :] = torch.bmm(math_utils.matrix_from_quat(self._offset_rot), jacobian[:, 3:, :])\n",
    "\n",
    "        return jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def apply_actions(self):\n",
    "        \"\"\"Applies the actions to the asset managed by the term.\n",
    "        Note: This is called at every simulation step by the manager.\n",
    "        \"\"\"\n",
    "        output_torques = (torch.rand(self.num_envs, self._num_joints, device=self.device))# * 80) - 40\n",
    "\n",
    "        # print('--- Torch ---')\n",
    "        # print('shape : ',output_torques.shape)\n",
    "        # print('device : ',output_torques.device)\n",
    "        # print('Type : ', type(output_torques))\n",
    "        \n",
    "        output_torques_jax = torch_to_jax(output_torques)\n",
    "        output_torques_jax = (output_torques_jax * 80) - 40\n",
    "\n",
    "        # print('')\n",
    "        # print('--- Jax ---')\n",
    "        # print('Shape : ', output_torques_jax.shape)\n",
    "        # print('device : ',output_torques_jax.devices())\n",
    "        # print('Type : ', type(output_torques_jax))\n",
    "\n",
    "        output_torques2 = jax_to_torch(output_torques_jax)\n",
    "\n",
    "        # set joint effort targets (should be equivalent to torque) : Torque controlled robot\n",
    "        self._asset.set_joint_effort_target(output_torques2, joint_ids=self._joint_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_robot_state2(self):\n",
    "        \"\"\" TODO Write description\n",
    "        \"\"\"\n",
    "\n",
    "        # Joint Index\n",
    "        fl_joints = self._asset.find_joints(\"FL.*\")[0]\t\t# list [0, 4,  8]\n",
    "        fr_joints = self._asset.find_joints(\"FR.*\")[0]\t\t# list [1, 5,  9]\n",
    "        rl_joints = self._asset.find_joints(\"RL.*\")[0]\t\t# list [2, 6, 10]\n",
    "        rr_joints = self._asset.find_joints(\"RR.*\")[0]\t\t# list [3, 7, 11]\n",
    "\n",
    "        # Body Index\n",
    "        foot_idx = self._asset.find_bodies(\".*foot\")[0]\n",
    "\n",
    "        # 'FL_foot', 'FR_foot', 'RL_foot', 'RR_foot'\n",
    "        fl_jacobian = self._asset.root_physx_view.get_jacobians()[:, foot_idx[0], 0:3, fl_joints]# + 6]\n",
    "        fr_jacobian = self._asset.root_physx_view.get_jacobians()[:, foot_idx[1], 0:3, fr_joints]# + 6]\n",
    "        rl_jacobian = self._asset.root_physx_view.get_jacobians()[:, foot_idx[2], 0:3, rl_joints]# + 6]\n",
    "        rr_jacobian = self._asset.root_physx_view.get_jacobians()[:, foot_idx[3], 0:3, rr_joints]# + 6]\n",
    "\n",
    "        # foot position in wf\n",
    "        fl_foot_pos_w = self._asset.data.body_state_w[:, foot_idx[0], 0:3]\n",
    "        fr_foot_pos_w = self._asset.data.body_state_w[:, foot_idx[1], 0:3]\n",
    "        rl_foot_pos_w = self._asset.data.body_state_w[:, foot_idx[2], 0:3]\n",
    "        rr_foot_pos_w = self._asset.data.body_state_w[:, foot_idx[3], 0:3]\n",
    "\n",
    "        # foot orientation in wf\n",
    "        fl_foot_orient_w = self._asset.data.body_state_w[:, foot_idx[0], 3:7]\n",
    "        fr_foot_orient_w = self._asset.data.body_state_w[:, foot_idx[1], 3:7]\n",
    "        rl_foot_orient_w = self._asset.data.body_state_w[:, foot_idx[2], 3:7]\n",
    "        rr_foot_orient_w = self._asset.data.body_state_w[:, foot_idx[3], 3:7]\n",
    "\n",
    "        # Root state ``[pos, quat, lin_vel, ang_vel]`` in simulation world frame. Shape is (num_instances, 13)\n",
    "        base_pose_w = self._asset.data.root_state_w[:, 0:3]\n",
    "        base_orient_w = self._asset.data.root_state_w[:, 3:7]\n",
    "        base_lin_vel_w = self._asset.data.root_state_w[:, 7:10]\n",
    "        base_ang_vel_w = self._asset.data.root_state_w[:, 10:13]\n",
    "\n",
    "        # foot position, orientation in bf\n",
    "        fl_foot_pos_b, fl_foot_orient_b = math_utils.subtract_frame_transforms(base_pose_w, base_orient_w, fl_foot_pos_w, fl_foot_orient_w)\n",
    "        fr_foot_pos_b, fr_foot_orient_b = math_utils.subtract_frame_transforms(base_pose_w, base_orient_w, fr_foot_pos_w, fr_foot_orient_w)\n",
    "        rl_foot_pos_b, rl_foot_orient_b = math_utils.subtract_frame_transforms(base_pose_w, base_orient_w, rl_foot_pos_w, rl_foot_orient_w)\n",
    "        rr_foot_pos_b, rr_foot_orient_b = math_utils.subtract_frame_transforms(base_pose_w, base_orient_w, rr_foot_pos_w, rr_foot_orient_w)\n",
    "\n",
    "        # foot joint position\n",
    "        fl_joint_pos = self._asset.data.joint_pos[:, fl_joints]\n",
    "        fr_joint_pos = self._asset.data.joint_pos[:, fr_joints]\n",
    "        rl_joint_pos = self._asset.data.joint_pos[:, rl_joints]\n",
    "        rr_joint_pos = self._asset.data.joint_pos[:, rr_joints]\n",
    "\n",
    "        # foot joint velocity\n",
    "        fl_joint_vel = self._asset.data.joint_vel[:, fl_joints]\n",
    "        fr_joint_vel = self._asset.data.joint_vel[:, fr_joints]\n",
    "        rl_joint_vel = self._asset.data.joint_vel[:, rl_joints]\n",
    "        rr_joint_vel = self._asset.data.joint_vel[:, rr_joints]\n",
    "\n",
    "        print('alo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stance Leg controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor Shape: torch.Size([2, 4, 3, 5])\n",
      "Random Tensor:\n",
      "tensor([[[[-1.0008,  0.7120, -0.1742, -1.4273, -0.2322],\n",
      "          [ 0.4963, -0.0760,  0.7140,  0.5691, -0.4790],\n",
      "          [-0.2406,  0.7622,  0.0441, -2.3687,  0.6843]],\n",
      "\n",
      "         [[-1.1865, -0.2030, -0.8373,  1.5632, -0.9582],\n",
      "          [-1.6118,  0.9994,  0.2950,  1.7622, -0.6367],\n",
      "          [-0.9983,  0.1925,  1.1585, -0.3202, -0.7383]],\n",
      "\n",
      "         [[ 0.9787,  0.0971,  0.9300, -1.4056,  0.0978],\n",
      "          [-0.8115,  0.1189,  1.5842,  0.1966,  1.0970],\n",
      "          [-0.2550, -2.1972, -0.2008, -0.6315,  0.5687]],\n",
      "\n",
      "         [[ 0.8719, -0.0730, -0.2174,  0.8004, -0.7905],\n",
      "          [ 0.4587, -0.1622,  0.8989,  1.1916,  0.8667],\n",
      "          [ 0.1111, -1.7449,  0.0858,  1.7471,  0.4848]]],\n",
      "\n",
      "\n",
      "        [[[-2.6416,  1.3883,  1.4118, -0.1556, -0.0260],\n",
      "          [ 0.0520, -1.5354, -0.1618, -0.0765,  0.7076],\n",
      "          [ 0.6039, -0.3753, -0.7691,  0.4189, -1.3773]],\n",
      "\n",
      "         [[-0.7048,  1.1861, -0.2367, -0.0804,  0.8997],\n",
      "          [ 1.2829, -0.1929, -0.9965, -0.4421,  0.7688],\n",
      "          [-1.1038, -0.4555, -0.1341,  0.7287,  0.5386]],\n",
      "\n",
      "         [[ 2.1951, -0.3242, -0.6417,  0.2766, -0.3449],\n",
      "          [ 1.1949,  0.4038,  0.8481, -0.8909,  1.4892],\n",
      "          [ 2.1680,  0.3773, -1.4098,  0.2815, -1.8475]],\n",
      "\n",
      "         [[-0.1910, -0.9337, -0.8457,  2.0190,  0.9930],\n",
      "          [-0.3845, -0.0142,  1.1648,  0.6924,  0.3329],\n",
      "          [ 0.6188,  0.0251, -0.0031, -0.2717,  1.0208]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define symbolic variables\n",
    "batch_size = 2\n",
    "num_legs = 4\n",
    "num_joints_per_leg = 5\n",
    "\n",
    "# Instantiate the tensor with symbolic shape\n",
    "shape = (batch_size, num_legs, 3, num_joints_per_leg)\n",
    "tensor = torch.randn(*shape)\n",
    "\n",
    "print(\"Random Tensor Shape:\", tensor.shape)\n",
    "print(\"Random Tensor:\")\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean Tensor Shape: torch.Size([2, 4])\n",
      "Boolean Tensor:\n",
      "tensor([[ True,  True, False, False],\n",
      "        [False,  True, False,  True]])\n"
     ]
    }
   ],
   "source": [
    "c0 = torch.randint(0, 2, (batch_size, num_legs), dtype=torch.bool)\n",
    "\n",
    "print(\"Boolean Tensor Shape:\", c0.shape)\n",
    "print(\"Boolean Tensor:\")\n",
    "print(c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian = torch.randn(batch_size, num_legs, 3, num_joints_per_leg)\n",
    "F0_star = torch.randn(batch_size, num_legs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian   shape : torch.Size([2, 4, 3, 5])\n",
      "Jacobian.T shape : torch.Size([2, 4, 5, 3])\n",
      "   GRF     shape : torch.Size([2, 4, 3])\n",
      "   GRF 2   shape : torch.Size([2, 4, 3, 1])\n",
      "     q     shape : torch.Size([2, 4, 5, 1])\n",
      "     q2    shape : torch.Size([2, 4, 5])\n",
      "\n",
      "Jacobian : \n",
      "tensor([[ 1.8449, -0.1331, -0.4473, -0.3967, -0.5775],\n",
      "        [-0.1599, -0.0411,  0.1473, -0.2492,  1.2638],\n",
      "        [-1.4937, -1.0205, -0.9950,  0.1527,  1.4755]])\n",
      "\n",
      "GRF : \n",
      "tensor([ 0.8727, -0.0659, -0.1853])\n",
      "\n",
      "Joints : \n",
      "tensor([-1.1362, -1.4506, -0.6089,  2.4870,  1.3955])\n",
      "\n",
      "Torques : \n",
      "tensor([[[-0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "         [-1.8240,  0.8967, -0.6014,  0.1919,  0.6543],\n",
      "         [-0.0195, -0.1334, -1.3107,  0.5556, -2.4532]],\n",
      "\n",
      "        [[ 0.4518,  1.8152,  1.0578, -2.1407,  0.1980],\n",
      "         [-0.0000, -0.0000,  0.0000,  0.0000, -0.0000],\n",
      "         [-1.1362, -1.4506, -0.6089,  2.4870,  1.3955],\n",
      "         [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jacobian = torch.randn(batch_size, num_legs, 3, num_joints_per_leg)\n",
    "jacobian_T = jacobian.transpose(-1,-2).detach().clone() # Transpose last two dimensions\n",
    "print('Jacobian   shape :',jacobian.shape)\n",
    "print('Jacobian.T shape :',jacobian_T.shape)\n",
    "\n",
    "# F0_star = torch.randn(batch_size, num_legs, 3)\n",
    "F0_star2 = F0_star.unsqueeze(-1).detach().clone() \n",
    "print('   GRF     shape :',F0_star.shape)\n",
    "print('   GRF 2   shape :',F0_star2.shape)\n",
    "\n",
    "q = torch.matmul(jacobian_T, F0_star.unsqueeze(-1))\n",
    "q2 = q.squeeze(-1).clone().detach()\n",
    "print('     q     shape :',q.shape)\n",
    "print('     q2    shape :',q2.shape)\n",
    "\n",
    "print('')\n",
    "print('Jacobian : ')\n",
    "print(jacobian[1,3,:,:])\n",
    "\n",
    "print('')\n",
    "print('GRF : ')\n",
    "print(F0_star[1,3,:])\n",
    "\n",
    "print('')\n",
    "print('Joints : ')\n",
    "print(q2[1,2,:])\n",
    "\n",
    "T = q2 * ~c0.unsqueeze(-1).expand(*[-1] * len(c0.shape), T.shape[-1])\n",
    "print('')\n",
    "print('Torques : ')\n",
    "print(T[:,:,:])\n",
    "\n",
    "T.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5])\n",
      "tensor([[[-0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "         [-1.8240,  0.8967, -0.6014,  0.1919,  0.6543],\n",
      "         [-0.0195, -0.1334, -1.3107,  0.5556, -2.4532]],\n",
      "\n",
      "        [[ 0.4518,  1.8152,  1.0578, -2.1407,  0.1980],\n",
      "         [-0.0000, -0.0000,  0.0000,  0.0000, -0.0000],\n",
      "         [-1.1362, -1.4506, -0.6089,  2.4870,  1.3955],\n",
      "         [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]])\n",
      "tensor([[-0.0000,  0.0000,  0.6543, -2.4532],\n",
      "        [ 0.1980, -0.0000,  1.3955, -0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(T.shape)\n",
    "print(T)\n",
    "print(T[:,:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian     Shape: torch.Size([2, 4, 3, 5])\n",
      "Jacobian dot Shape: torch.Size([2, 4, 3, 5])\n",
      "     q   dot Shape: torch.Size([2, 4, 5])\n",
      "Mass Matrix  Shape: torch.Size([2, 4, 5, 5])\n",
      "     h       Shape: torch.Size([2, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define symbolic variables\n",
    "batch_size = 2\n",
    "num_legs = 4\n",
    "num_joints_per_leg = 5\n",
    "\n",
    "jacobian = torch.randn(batch_size, num_legs, 3, num_joints_per_leg)\n",
    "jacobian_dot = torch.randn(batch_size, num_legs, 3, num_joints_per_leg)\n",
    "q_dot = torch.randn(batch_size, num_legs, num_joints_per_leg)\n",
    "mass_matrix = torch.randn(batch_size, num_legs, num_joints_per_leg, num_joints_per_leg)\n",
    "h = torch.randn(batch_size, num_legs, num_joints_per_leg)\n",
    "\n",
    "print(\"Jacobian     Shape:\", jacobian.shape)\n",
    "print(\"Jacobian dot Shape:\", jacobian_dot.shape)\n",
    "print(\"     q   dot Shape:\", q_dot.shape)\n",
    "print(\"Mass Matrix  Shape:\", mass_matrix.shape)\n",
    "print(\"     h       Shape:\", h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   J_dot_x_q_dot Shape: torch.Size([2, 4, 3])\n",
      "                   jacobian_inv  Shape: torch.Size([2, 4, 5, 3])\n",
      "     J[p_dot_dot - J(q)*q_dot] Shape: torch.Size([2, 4, 5])\n",
      "M(q)*J[p_dot_dot - J(q)*q_dot] Shape: torch.Size([2, 4, 5])\n",
      "                              T  Shape: torch.Size([2, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "J_dot_x_q_dot = torch.matmul(jacobian_dot, q_dot.unsqueeze(-1)).squeeze(-1)\n",
    "print(\"                   J_dot_x_q_dot Shape:\", J_dot_x_q_dot.shape)\n",
    "\n",
    "jacobian_inv = torch.linalg.pinv(jacobian)\n",
    "print(\"                   jacobian_inv  Shape:\", jacobian_inv.shape)\n",
    "\n",
    "J_inv_p_dot_dot_min_J_dot_x_q_dot = torch.matmul(jacobian_inv, J_dot_x_q_dot.unsqueeze(-1)).squeeze(-1)\n",
    "print(\"     J[p_dot_dot - J(q)*q_dot] Shape:\", J_inv_p_dot_dot_min_J_dot_x_q_dot.shape)\n",
    "\n",
    "M_J_inv_p_dot_dot_min_J_dot_x_q_dot = torch.matmul(mass_matrix, J_inv_p_dot_dot_min_J_dot_x_q_dot.unsqueeze(-1)).squeeze(-1)\n",
    "print('M(q)*J[p_dot_dot - J(q)*q_dot] Shape:', M_J_inv_p_dot_dot_min_J_dot_x_q_dot.shape)\n",
    "\n",
    "# Final step\n",
    "T = torch.add(M_J_inv_p_dot_dot_min_J_dot_x_q_dot, h)\n",
    "print('                              T  Shape:', T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 17, 6, 18])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define symbolic variables\n",
    "batch_size = 5\n",
    "num_legs = 4\n",
    "num_joints_per_leg = 3\n",
    "\n",
    "_foot_idx = [13,14,15,16]\n",
    "_joint_idx = [[0,4,8],[1,5,9],[2,6,10],[3,7,11]]\n",
    "# _joint_idx = [[[[0,4,8]],[[1,5,9]],[[2,6,10]],[[3,7,11]]]]\n",
    "_joint_idx_tensor = torch.Tensor(_joint_idx)\n",
    "\n",
    "jacobian = torch.randn(batch_size, 17, 6, 18)\n",
    "print(jacobian.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 3, 18])\n",
      "0\n",
      "[0, 4, 8]\n",
      "1\n",
      "[1, 5, 9]\n",
      "2\n",
      "[2, 6, 10]\n",
      "3\n",
      "[3, 7, 11]\n"
     ]
    }
   ],
   "source": [
    "print(jacobian[:,_foot_idx,:3,:].shape)\n",
    "\n",
    "for leg_i, joints_in_leg_i in enumerate(_joint_idx):\n",
    "    print(leg_i)\n",
    "    print(joints_in_leg_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 3, 3])\n",
      "torch.Size([5, 3, 3, 3])\n",
      "torch.Size([5, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "jacob1 = jacobian[:, 0, :3, [0,4,8]].unsqueeze(1)\n",
    "jacob2 = jacobian[:, 1, :3, [1,5,9]].unsqueeze(1)\n",
    "jacob3 = jacobian[:, 2, :3, [2,6,10]].unsqueeze(1)\n",
    "print(jacob1.shape)\n",
    "print(torch.cat((jacob1, jacob2, jacob3), dim=1).shape)\n",
    "\n",
    "jacob = []\n",
    "jacob.append(jacobian[:, 0, :3, 6+np.asarray([0,4,8])].unsqueeze(1))\n",
    "jacob.append(jacobian[:, 1, :3, [1,5,9]].unsqueeze(1))\n",
    "jacob.append(jacobian[:, 2, :3, [2,6,10]].unsqueeze(1))\n",
    "print(torch.cat((jacob), dim=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 2.0000, 2.1000],\n",
      "         [3.0000, 4.0000, 4.1000]],\n",
      "\n",
      "        [[5.0000, 6.0000, 6.1000],\n",
      "         [7.0000, 8.0000, 8.1000]]])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 3.0000, 2.0000, 4.0000, 2.1000, 4.1000],\n",
       "        [5.0000, 7.0000, 6.0000, 8.0000, 6.1000, 8.1000]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[[1.0, 2.0, 2.1], [3.0, 4.0, 4.1]], [[5,6, 6.1] , [7, 8, 8.1]]])\n",
    "print(a)\n",
    "print()\n",
    "a.permute(0,2,1).reshape(2,6)\n",
    "# a.view(2,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Touch Down Pos : Convolutions\n",
    "\n",
    "        # Utiliser une convolution sur c (contact sequence) pour trouver le point de dpart et d'arriver du pied.\n",
    "        # Avec un filtre genre f = [0, 1], pour ne garder que les flancs montants\n",
    "        # Imaginons p = [p1, p2, p3, p4, p5, p6, p7, p8, p9, p10]\n",
    "        #           c = [ 1,  1,  0,  0,  0,  1,  1,  0,  0,   1]\n",
    "        # Les points de dpart serait p1, p6 et p10 les points d'arriv p6 et p10\n",
    "        # Il faudrait retourner qqch comme \n",
    "        #        key =  [1,   0,  0,  0,  0,  1,  0,  0,  0,   1]\n",
    "        # Qui permetrait d'extraire facilement [p1, p6, p10] avec p[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 1., 0., 0., 0., 1., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 1., 0., 1., 0.],\n",
       "         [0., 0., 0., 1., 0., 1., 0., 0., 1., 0.]]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 2\n",
    "num_legs = 4\n",
    "time_horizon = 10\n",
    "\n",
    "c = torch.empty(batch_size, num_legs, time_horizon).bernoulli(0.2)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -0.0000, -0.0000, -0.0000,  0.2320, -0.0000, -0.0000,\n",
       "           0.0000,  0.2659, -1.4655],\n",
       "         [ 0.0000, -0.0000,  0.6376,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  1.6942,  0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  1.2197,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          -0.0000, -0.3521,  0.0000],\n",
       "         [ 0.6727,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.4122,\n",
       "           0.0000, -0.0000,  0.0000],\n",
       "         [ 1.9076,  0.0000,  0.0000, -0.0000,  3.6689, -0.0000, -0.4448,\n",
       "          -0.0000,  0.4419,  0.0000],\n",
       "         [-0.0000,  0.0000, -0.0000, -0.7543, -0.0000,  0.6289,  0.0000,\n",
       "           0.0000, -1.0148,  0.0000]]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.randn(c.shape)\n",
    "p2 = p * c\n",
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 2, 0, 8],\n",
       "        [8, 0, 0, 3]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indx = torch.argmax((c!=0).float(), dim=-1)\n",
    "indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2320,  0.6376,  1.4360,  1.2197],\n",
       "        [-0.3521,  0.6727,  1.9076, -0.7543]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(p, -1, indx.unsqueeze(-1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected padding to be a single integer value or a list of 1 values to match the convolution dimensions, but got padding=[0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m kernel \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      2\u001b[0m kernel \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected padding to be a single integer value or a list of 1 values to match the convolution dimensions, but got padding=[0, 1]"
     ]
    }
   ],
   "source": [
    "kernel = torch.tensor([-1, 1], dtype=torch.float32)\n",
    "kernel = kernel.unsqueeze(0).unsqueeze(0).expand(4,1,2)\n",
    "torch.conv1d(c, kernel, groups=4, padding=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.,  1.])\n",
      "torch.Size([2])\n",
      "\n",
      "tensor([[[-1.,  1.]],\n",
      "\n",
      "        [[-1.,  1.]],\n",
      "\n",
      "        [[-1.,  1.]],\n",
      "\n",
      "        [[-1.,  1.]]])\n",
      "torch.Size([4, 1, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(kernel)\n",
    "print(kernel.shape)\n",
    "print()\n",
    "\n",
    "kernel2 = kernel.unsqueeze(0).unsqueeze(0).expand(4,1,2)\n",
    "print(kernel2)\n",
    "print(kernel2.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[[1,1,1,1],[2,2,2,2],[3,3,3,3]], [[4,4,4,4], [5,5,5,5], [6,6,6,6]]]).transpose(-1,-2)\n",
    "b = torch.tensor([[[1,2,3,4],[2,2,2,2],[3,3,3,3]], [[4,4,4,4], [5,5,5,5], [6,6,6,6]]]).transpose(-1,-2)\n",
    "print(a.shape)\n",
    "\n",
    "c = torch.cat((a,b), dim=1)\n",
    "c.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0.9700, 0.4700, 0.3033],\n",
      "        [0.2200, 0.1700, 0.1367]])\n",
      "\n",
      "tensor([[0.9000, 0.8000, 0.7000],\n",
      "        [0.6000, 0.5000, 0.4000]])\n",
      "\n",
      "tensor([[0.9000, 0.4000, 0.2333],\n",
      "        [0.1500, 0.1000, 0.0667]])\n",
      "\n",
      "tensor([[0.9700, 0.4700, 0.3033],\n",
      "        [0.2200, 0.1700, 0.1367]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "f = torch.tensor([[1,2,3], [4, 5, 6]])\n",
    "d = torch.tensor([[0.1,0.2,0.3], [0.4, 0.5, 0.6]])\n",
    "print(f.shape)\n",
    "print(d.shape)\n",
    "\n",
    "swing_period = ((1-d) / f) + 0.07\n",
    "print(swing_period.shape)\n",
    "print(swing_period)\n",
    "print()\n",
    "print(1-d)\n",
    "print()\n",
    "print((1-d)/f)\n",
    "print()\n",
    "print((1-d)/f + 0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1],\n",
       "        [4, 5, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[:,-1] = 1\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True, False, False],\n",
      "        [False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.empty(2, 3).bernoulli(0.5).bool()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.2000, 0.3000],\n",
       "        [0.4000, 0.5000, 0.6000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f * c) + (d * ~c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 2.0000, 0.0500],\n",
       "         [1.5000, 2.0000, 0.0500],\n",
       "         [2.0000, 2.0000, 0.0500],\n",
       "         [2.5000, 2.0000, 0.0500]],\n",
       "\n",
       "        [[4.0000, 5.0000, 0.0500],\n",
       "         [4.0000, 5.0000, 0.0500],\n",
       "         [4.0000, 5.0000, 0.0500],\n",
       "         [4.0000, 5.0000, 0.0500]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a.shape[:-1])\n",
    "x = (a[:,:,:2] + b[:,:,:2]) / 2\n",
    "torch.cat((x,0.05*torch.ones_like(a[:,:, :1])), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.2000, 0.3000],\n",
      "        [0.4000, 0.5000, 0.6000]])\n",
      "\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.0400, 0.0270],\n",
       "        [0.0256, 0.0312, 0.0467]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(d)\n",
    "print()\n",
    "print(f)\n",
    "print()\n",
    "\n",
    "d**f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3])\n",
      "\n",
      "tensor([[[1, 2, 3],\n",
      "         [1, 2, 3],\n",
      "         [1, 2, 3],\n",
      "         [1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6],\n",
      "         [4, 5, 6],\n",
      "         [4, 5, 6],\n",
      "         [4, 5, 6]]])\n",
      "tensor([[2, 2, 2, 2],\n",
      "        [5, 5, 5, 5]])\n",
      "torch.Size([2, 4])\n",
      "\n",
      "tensor([[2, 2, 2, 2],\n",
      "        [5, 5, 5, 5]])\n",
      "torch.Size([2, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print()\n",
    "print(a)\n",
    "\n",
    "print(a[..., 1])\n",
    "print(a[..., 1].shape)\n",
    "print()\n",
    "\n",
    "print(a[:,:, 1])\n",
    "print(a[:,:, 1].shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.devices()\n",
    "\n",
    "import os\n",
    "print(os.environ.get(\"CUDA_HOME\"))  # Check CUDA_HOME\n",
    "print(os.environ.get(\"LD_LIBRARY_PATH\"))  # Check LD_LIBRARY_PATH (Linux/macOS)\n",
    "print(os.environ.get(\"PATH\"))  # Check PATH (Windows)\n",
    "\n",
    "print('-------------')\n",
    "import torch\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " p0 shape : torch.Size([3, 4, 3])\n",
      " p1 shape : torch.Size([3, 4, 3])\n",
      " p2 shape : torch.Size([3, 4, 3])\n",
      " is_S0 shape : torch.Size([3, 4, 3])\n",
      "\n",
      " cp1 shape : torch.Size([3, 4, 3])\n",
      " cp2 shape : torch.Size([3, 4, 3])\n",
      " cp3 shape : torch.Size([3, 4, 3])\n",
      " cp4 shape : torch.Size([3, 4, 3])\n",
      " time_fac shape : torch.Size([3, 4])\n",
      " t shape : torch.Size([3, 4])\n",
      "\n",
      "time traj shape : torch.Size([3, 4, 5])\n",
      "\n",
      "time traj shape : torch.Size([3, 4, 1, 5])\n",
      " cp1 shape : torch.Size([3, 4, 3, 1])\n",
      " cp2 shape : torch.Size([3, 4, 3, 1])\n",
      " cp3 shape : torch.Size([3, 4, 3, 1])\n",
      " cp4 shape : torch.Size([3, 4, 3, 1])\n",
      "\n",
      "desired_foot_pos_traj shape : torch.Size([3, 4, 3, 5])\n",
      "desired_foot_vel_traj shape : torch.Size([3, 4, 3, 5])\n",
      "desired_foot_acc_traj shape : torch.Size([3, 4, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\"\"\" Given feet position sequence and contact sequence -> compute swing trajectories by fitting a cubic spline between\n",
    "the lift-off and the touch down define in the contact sequence. \n",
    "- Swing frequency and duty cycle are used to compute the swing period\n",
    "- A middle point is used for the interpolation : which is heuristically defined. It defines the step height\n",
    "- p1 (middle point) and p2 (touch-down) are updated each time, while p0 is conserved (always the same lift off position)\n",
    "\n",
    "Args:\n",
    "    - p   (torch.Tensor): Foot position sequence                of shape(batch_size, num_legs, 3, time_horizon)\n",
    "    - c   (torch.Tensor): Foot contact sequence                 of shape(c)\n",
    "    - f   (torch.Tensor): Leg frequency                         of shape(batch_size, num_legs)\n",
    "    - d   (torch.Tensor): Stepping duty cycle                   of shape(batch_size, num_legs)\n",
    "    - decimation   (int): Number of timestep for the traj.\n",
    "\n",
    "Returns:\n",
    "    - pt  (torch.Tensor): Desired Swing Leg trajectories        of shape(batch_size, num_legs, 9, decimation)   (9 = xyz_pos, xzy_vel, xyz_acc)\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 3\n",
    "num_legs = 4\n",
    "time_horizon = 5\n",
    "dt_out = 0.1\n",
    "dt_in = 0.1\n",
    "\n",
    "d = torch.randn(batch_size, num_legs)\n",
    "f = torch.randn(batch_size, num_legs)\n",
    "p = torch.randn(batch_size, num_legs, 3, time_horizon)\n",
    "c = torch.empty(batch_size, num_legs, time_horizon).bernoulli(0.5).bool()\n",
    "c_prev = torch.randn(batch_size, num_legs)\n",
    "p0 = torch.randn(batch_size, num_legs, 3)\n",
    "swing_time = torch.randn(batch_size, num_legs)\n",
    "\n",
    "\n",
    "# Step 0. Define and Compute usefull variables\n",
    "\n",
    "# Heuristic TODO Save that on the right place, could also be a RL variable\n",
    "step_height = 0.05\n",
    "\n",
    "# Time during wich the leg is in swing. TODO Why +0.07 ? Is it an heuristic also ?\n",
    "# Shape (batch_size, num_legs)\n",
    "swing_period = ((1-d) / f) + 0.07\n",
    "\n",
    "half_swing_period = swing_period / 2\n",
    "time_fac = 1 / (swing_period / 2) #bezier_time_factor\n",
    "\n",
    "\n",
    "# Step 1. Retrieve the three interpolation points : p0, p1, p2 (lift-off, middle point, touch down)\n",
    "\n",
    "# Retrieve p0 : If c(0)=0 and c(-1)=1 : The leg lift-off -> p0 = p(0) # TODO p(0) or must it be from simulation data ? TODO Must it be p(0) or p(-1)\n",
    "# Update only the p0 that are new lift off positions (unsqueeze lifting off -> shape(batc_size, num_legs, 1) to make it compatible for multiplication with p shape)\n",
    "# shape (batch_size, num_legs, 3) \n",
    "lifting_off = ((c[:,:,0]==0) * (c_prev == 1)).unsqueeze(-1)\n",
    "p0 = (p[:,:,:,0] * lifting_off) + (p0 * ~lifting_off)  \n",
    "\n",
    "# Retrieve p2 : Retrieve the index of the touch down in the contact sequence : First Non-zero Index : shape(batch_size, num_legs)\n",
    "# Set the last value of c as ONE to avoid the case of only 0 in the contact sequence, wich return the first element (make more sense to retrun the last)\n",
    "# With the touch_down index, retrieve the touch down foot position : p2. !!! Need to chanhe Idx shape from (batch_size, num_legs) to (batch_size, num_legs, 3, 1)!!!\n",
    "# shape (batch_size, num_legs, 3) \n",
    "c[:,:,-1] = 1 # TODO Does it modify c also outside this function ?\n",
    "first_non_zero_indx = torch.argmax((c!=0).float(), dim=-1)\n",
    "\n",
    "# print(' p shape :', p.shape)\n",
    "# print(' Idx shape :', first_non_zero_indx.shape)\n",
    "# print(first_non_zero_indx)\n",
    "# print()\n",
    "# print(' Idx shape :', first_non_zero_indx.unsqueeze(-1).expand(-1,-1,3).shape)\n",
    "# print(first_non_zero_indx.unsqueeze(-1).expand(-1,-1,3))\n",
    "# print()\n",
    "# print()\n",
    "p2 = torch.gather(p, -1, first_non_zero_indx.unsqueeze(-1).unsqueeze(-1)).squeeze(-1)\n",
    "p2 = torch.gather(p, -1, first_non_zero_indx.unsqueeze(-1).expand(-1,-1,3).unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "# Retrieve p1 : (x,y) position are define as the middle point between p0 and p1 (lift-off and touch-down). z is heuristcally define\n",
    "# shape (batch_size, num_legs, 3)\n",
    "p1 = (p0[:,:,:2] + p2[:,:,:2]) / 2     # p1(x,y) is in the middle of p0 and p2\n",
    "p1 = torch.cat((p1, step_height*torch.ones_like(p1[:,:,:1])), dim=2) # Append a third dimension z : defined as step_height\n",
    "\n",
    "# Step 2. Compute the parameters for the interpolation\n",
    "\n",
    "# Swing time : reset if lifting off, then increment by one time step (outer loop) (squeeze lifting_off : (batch_size, num_legs, 1)->(batch_size, num_legs))\n",
    "# then compute t in [0, Delta_t/2], which would be use for the spline interpolation\n",
    "# shape (batch_size, num_legs)\n",
    "# print()\n",
    "# print(' swing_time shape :', swing_time.shape)\n",
    "# print(' lifting_off shape :', lifting_off.shape)\n",
    "swing_time = (swing_time * ~lifting_off.squeeze(-1)) + dt_out\n",
    "t = swing_time % half_swing_period  # Swing time (half)\n",
    "\n",
    "# Compute the a,b,c,d polynimial coefficient for the cubic interpolation S(t) = a*t^3 + b*t^2 + c*t + d\n",
    "# If swing_time < swing period/2 -> S_0(t) (ie. first interpolation), otherwise -> S_1(t - delta_t/2) (ie. second interpolation)\n",
    "# cp_x shape (batch_size, num_legs, 3)\n",
    "print()\n",
    "print(' p0 shape :', p0.shape)\n",
    "print(' p1 shape :', p1.shape)\n",
    "print(' p2 shape :', p2.shape)\n",
    "print(' is_S0 shape :', is_S0.shape)\n",
    "\n",
    "is_S0 = (swing_time <=  half_swing_period).unsqueeze(-1).expand(*[-1] * len(swing_time.shape), 3)  # shape (batch_size, num_legs, 3)\n",
    "cp1 = (p0 * is_S0)                                         + (p1 * ~is_S0)\n",
    "cp2 = (p0 * is_S0)                                         + (torch.cat((p2[:,:,:2], p1[:,:,2:]), dim=2)* ~is_S0)\n",
    "cp3 = (torch.cat((p0[:,:,:2], p1[:,:,2:]), dim=2) * is_S0) + (p2 * ~is_S0)\n",
    "cp4 = (p1 * is_S0)                                              + (p2 * ~is_S0)\n",
    "\n",
    "print()\n",
    "print(' cp1 shape :', cp1.shape)\n",
    "print(' cp2 shape :', cp2.shape)\n",
    "print(' cp3 shape :', cp3.shape)\n",
    "print(' cp4 shape :', cp4.shape)\n",
    "print(' time_fac shape :', time_fac.shape)\n",
    "print(' t shape :', t.shape)\n",
    "\n",
    "\n",
    "# time_fac, t : shape(batch_size, num_legs) -> unsqueezed(-1) -> Shape (batch_size, num_legs, 1)\n",
    "# (arrange = [0,1,2,...])*dt.unsqueeze(0).unsqueeze(-1)       -> Shape (1, 1, time_horizon)\n",
    "# time traj : Shape (batch_size, num_legs, time_horizon)\n",
    "time_traj = (time_fac*t).unsqueeze(-1) + (torch.arange(time_horizon)*dt_in).unsqueeze(0).unsqueeze(0)\n",
    "print()\n",
    "print('time traj shape :', time_traj.shape)\n",
    "\n",
    "cp1 = cp1.unsqueeze(-1)\n",
    "cp2 = cp2.unsqueeze(-1)\n",
    "cp3 = cp3.unsqueeze(-1)\n",
    "cp4 = cp4.unsqueeze(-1)\n",
    "\n",
    "time_traj = time_traj.unsqueeze(2)\n",
    "print()\n",
    "print('time traj shape :', time_traj.shape)\n",
    "print(' cp1 shape :', cp1.shape)\n",
    "print(' cp2 shape :', cp2.shape)\n",
    "print(' cp3 shape :', cp3.shape)\n",
    "print(' cp4 shape :', cp4.shape)\n",
    "\n",
    "\n",
    "# Step 3. Compute the interpolation trajectory\n",
    "desired_foot_pos_traj = cp1*(1 - time_traj)**3 + 3*cp2*(time_traj)*(1 - time_traj)**2 + 3*cp3*((time_traj)**2)*(1 - time_traj) + cp4*(time_traj)**3\n",
    "desired_foot_vel_traj = 3*(cp2 - cp1)*(1 - time_traj)**2 + 6*(cp3 - cp2)*(1 - time_traj)*(time_traj) + 3*(cp4 - cp3)*(time_traj)**2\n",
    "desired_foot_acc_traj = 6*(1 - time_traj) * (cp3 - 2*cp2 + cp1) + 6 * (time_traj) * (cp4 - 2*cp3 + cp2)\n",
    "pt = torch.cat((desired_foot_pos_traj, desired_foot_vel_traj, desired_foot_acc_traj), dim=2)\n",
    "\n",
    "print()\n",
    "print('desired_foot_pos_traj shape :', desired_foot_pos_traj.shape)\n",
    "print('desired_foot_vel_traj shape :', desired_foot_vel_traj.shape)\n",
    "print('desired_foot_acc_traj shape :', desired_foot_acc_traj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swing_trajectory_generator(self, p: torch.Tensor, c: torch.Tensor, f: torch.Tensor, d: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Given feet position sequence and contact sequence -> compute swing trajectories by fitting a cubic spline between\n",
    "        the lift-off and the touch down define in the contact sequence. \n",
    "        - Swing frequency and duty cycle are used to compute the swing period\n",
    "        - A middle point is used for the interpolation : which is heuristically defined. It defines the step height\n",
    "        - p1 (middle point) and p2 (touch-down) are updated each time, while p0 is conserved (always the same lift off position)\n",
    "\n",
    "        Args:\n",
    "            - p   (torch.Tensor): Foot position sequence                of shape(batch_size, num_legs, 3, time_horizon)\n",
    "            - c   (torch.Tensor): Foot contact sequence                 of shape(batch_size, num_legs, time_horizon)\n",
    "            - f   (torch.Tensor): Leg frequency                         of shape(batch_size, num_legs)\n",
    "            - d   (torch.Tensor): Stepping duty cycle                   of shape(batch_size, num_legs)\n",
    "\n",
    "        Returns:\n",
    "            - pt  (torch.Tensor): Desired Swing Leg trajectories        of shape(batch_size, num_legs, 9, decimation)   (9 = xyz_pos, xzy_vel, xyz_acc)\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 0. Define and Compute usefull variables\n",
    "\n",
    "        # Heuristic TODO Save that on the right place, could also be a RL variable\n",
    "        step_height = 0.05\n",
    "\n",
    "        # Time during wich the leg is in swing.(add small numerical value to denominator to avoid division by 0)\n",
    "        # Shape (batch_size, num_legs)\n",
    "        swing_period = ((1-d) / (f.abs()+1e-10))\n",
    "        half_swing_period = swing_period / 2\n",
    "        time_fac = 1 / ((swing_period.abs()+1e-10) / 2) #bezier_time_factor\n",
    "\n",
    "\n",
    "        # Step 1. Retrieve the three interpolation points : p0, p1, p2 (lift-off, middle point, touch down)\n",
    "\n",
    "        # Retrieve p0 : If c(0)=0 and c(-1)=1 : The leg lift-off -> p0 = p(-1) (value from simulation : the last value where c=1)\n",
    "        # Update only the p0 that are new lift off positions (unsqueeze lifting off -> shape(batc_size, num_legs, 1) to make it compatible for multiplication with p shape)\n",
    "        # p0 shape (batch_size, num_legs, 3) \n",
    "        lifting_off = ((c[:,:,0]==0) * (self.c_prev == 1)).unsqueeze(-1)  \n",
    "        self.p0 = (self.p_sim_prev * lifting_off) + (self.p0 * ~lifting_off)  \n",
    "\n",
    "        # Retrieve p2 : Retrieve the index of the touch down in the contact sequence : First Non-zero Index : shape(batch_size, num_legs)\n",
    "        # Set the last value of c as ONE to avoid the case of only 0 in the contact sequence, wich return the first element (make more sense to retrun the last)\n",
    "        # With the touch_down index, retrieve the touch down foot position : p2\n",
    "        # Idx shape : (batch_size, num_legs) -> must transform to (batch_size, num_legs, 3, 1) to retrieve position from p of shape (batch_size, num_legs, 3, time_horizon)\n",
    "        # p2 shape (batch_size, num_legs, 3) \n",
    "        c[:,:,-1] = 1 # TODO Does it modify c also outside this function ?\n",
    "        first_non_zero_indx = torch.argmax((c!=0).float(), dim=-1)\n",
    "        p2 = torch.gather(p, -1, first_non_zero_indx.unsqueeze(-1).expand(-1,-1,3).unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # Retrieve p1 : (x,y) position are define as the middle point between p0 and p1 (lift-off and touch-down). z is heuristcally define\n",
    "        # p1 shape (batch_size, num_legs, 3)\n",
    "        p1 = (self.p0[:,:,:2] + p2[:,:,:2]) / 2     # p1(x,y) is in the middle of p0 and p2\n",
    "        p1 = torch.cat((p1, step_height*torch.ones_like(p1[:,:,:1])), dim=2) # Append a third dimension z : defined as step_height\n",
    "\n",
    "        # Step 2. Compute the parameters for the interpolation\n",
    "\n",
    "        # Swing time : reset if lifting off, then increment by one time step (outer loop)  (squeeze lifting_off : (batch_size, num_legs, 1)->(batch_size, num_legs))\n",
    "        # then compute t in [0, Delta_t/2], which would be use for the spline interpolation\n",
    "        # t & swing_time shape (batch_size, num_legs)\n",
    "        self.swing_time = (self.swing_time * ~lifting_off.squeeze(-1)) + self._dt_out\n",
    "        t = self.swing_time % (half_swing_period.abs() + 1e-10)  # Swing time (half) : add small numerical value to avoid nan when % 0\n",
    "\n",
    "        # Compute the a,b,c,d polynimial coefficient for the cubic interpolation S(t) = a*t^3 + b*t^2 + c*t + d\n",
    "        # If swing_time < swing period/2 -> S_0(t) (ie. first interpolation), otherwise -> S_1(t - delta_t/2) (ie. second interpolation)\n",
    "        # cp_x shape (batch_size, num_legs, 3)\n",
    "        is_S0 = (self.swing_time <=  half_swing_period).unsqueeze(-1).expand(*[-1] * len(self.swing_time.shape), 3)  # shape (batch_size, num_legs, 3)\n",
    "        cp1 = (self.p0 * is_S0)                                         + (p1 * ~is_S0)\n",
    "        cp2 = (self.p0 * is_S0)                                         + (torch.cat((p2[:,:,:2], p1[:,:,2:]), dim=2)* ~is_S0)\n",
    "        cp3 = (torch.cat((self.p0[:,:,:2], p1[:,:,2:]), dim=2) * is_S0) + (p2 * ~is_S0)\n",
    "        cp4 = (p1 * is_S0)                                              + (p2 * ~is_S0)\n",
    "\n",
    "        # Step 3. Prepare parameters to compute interpolation trajectory in one operation -> matrix multiplication\n",
    "        \n",
    "        # Generate the time trajectory t -> [t, t + dt, t+ 2*dt,...]\n",
    "        # time_fac, t : shape(batch_size, num_legs) -> unsqueezed(-1) -> Shape (batch_size, num_legs, 1)\n",
    "        # (arrange = [0,1,2,...])*dt.unsqueeze(0).unsqueeze(-1)       -> Shape (1, 1, decimation)\n",
    "        # time traj : Shape (batch_size, num_legs, decimation)\n",
    "        t_traj = (time_fac*t).unsqueeze(-1) + (torch.arange(self._decimation, device=self._device)*self._dt_in).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # Prepare cp_x to be mutltiplied by the time traj :  shape(batch_size, num_leg, 3) -> (batch_size, num_leg, 3, 1)\n",
    "        cp1 = cp1.unsqueeze(-1)\n",
    "        cp2 = cp2.unsqueeze(-1)\n",
    "        cp3 = cp3.unsqueeze(-1)\n",
    "        cp4 = cp4.unsqueeze(-1)\n",
    "\n",
    "        # Prepare time traj to be multplied by cp_x : shape(batch_size, num_leg, decimation) -> (batch_size, num_leg, 1, decimation)\n",
    "        t_traj = t_traj.unsqueeze(2)\n",
    "\n",
    "\n",
    "        # Step 4. Compute the interpolation trajectory\n",
    "        # shape (batch_size, num_legs, 3, decimation)\n",
    "        desired_foot_pos_traj = cp1*(1 - t_traj)**3 + 3*cp2*(t_traj)*(1 - t_traj)**2 + 3*cp3*((t_traj)**2)*(1 - t_traj) + cp4*(t_traj)**3\n",
    "        desired_foot_vel_traj = 3*(cp2 - cp1)*(1 - t_traj)**2 + 6*(cp3 - cp2)*(1 - t_traj)*(t_traj) + 3*(cp4 - cp3)*(t_traj)**2\n",
    "        desired_foot_acc_traj = 6*(1 - t_traj) * (cp3 - 2*cp2 + cp1) + 6 * (t_traj) * (cp4 - 2*cp3 + cp2)\n",
    "\n",
    "        # shape (batch_size, num_legs, 9, decimation) (9 = xyz_pos, xzy_vel, xyz_acc)\n",
    "        pt = torch.cat((desired_foot_pos_traj, desired_foot_vel_traj, desired_foot_acc_traj), dim=2)\n",
    "\n",
    "        if(pt.isnan().any()):\n",
    "            print('alo')\n",
    "        return pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 3, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "J = torch.randn(10,4,3,3)\n",
    "R = torch.randn(10,3,3)\n",
    "\n",
    "torch.matmul(J,R.unsqueeze(1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Riccardo's Jacobian\n",
    "        from omni.isaac.orbit.managers import SceneEntityCfg\n",
    "\n",
    "        fl_entity_cfg = SceneEntityCfg(\"robot\", joint_names=[\"FL.*\"], body_names=[\"FL_foot\"])\n",
    "        fl_entity_cfg.resolve(self._env.scene)\n",
    "        fl_jacobi_idx = fl_entity_cfg.body_ids[0]\n",
    "        fl_jacobian = self._asset.root_physx_view.get_jacobians()[:, fl_jacobi_idx, :, np.array(fl_entity_cfg.joint_ids) + 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Retrieve p2 : Retrieve the index of the touch down in the contact sequence : First Non-zero Index : shape(batch_size, num_legs)\n",
    "        # Set the last value of c as ONE to avoid the case of only 0 in the contact sequence, wich return the first element (make more sense to retrun the last)\n",
    "        # With the touch_down index, retrieve the touch down foot position : p2\n",
    "        # Idx shape : (batch_size, num_legs) -> must transform to (batch_size, num_legs, 3, 1) to retrieve position from p of shape (batch_size, num_legs, 3, time_horizon)\n",
    "        # p2 shape (batch_size, num_legs, 3) \n",
    "        c[:,:,-1] = 1 # TODO Does it modify c also outside this function ?\n",
    "        first_non_zero_indx = torch.argmax((c!=0).float(), dim=-1)\n",
    "        p2 = torch.gather(p_b, -1, first_non_zero_indx.unsqueeze(-1).expand(-1,-1,3).unsqueeze(-1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def swing_trajectory_generator(self, p_lw: torch.Tensor, c: torch.Tensor, f: torch.Tensor, d: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Given feet position sequence and contact sequence -> compute swing trajectories by fitting a cubic spline between\n",
    "        the lift-off and the touch down define in the contact sequence. \n",
    "        - Swing frequency and duty cycle are used to compute the swing period\n",
    "        - A middle point is used for the interpolation : which is heuristically defined. It defines the step height\n",
    "        - p1 (middle point) and p2 (touch-down) are updated each time, while p0 is conserved (always the same lift off position)\n",
    "        Note :\n",
    "            The variable are in the 'local' world frame _wl. This notation is introduced to avoid confusion with the 'global' world frame, where all the batches coexists.\n",
    "        \n",
    "        Args:\n",
    "            - p_lw (trch.Tensor): Foot touch down postion in _lw        of shape(batch_size, num_legs, 3)\n",
    "            - c   (torch.Tensor): Foot contact sequence                 of shape(batch_size, num_legs, time_horizon)\n",
    "            - f   (torch.Tensor): Leg frequency                         of shape(batch_size, num_legs)\n",
    "            - d   (torch.Tensor): Stepping duty cycle                   of shape(batch_size, num_legs)\n",
    "\n",
    "        Returns:\n",
    "            - pt_lw (tch.Tensor): Desired Swing Leg traj. in _lw frame  of shape(batch_size, num_legs, 9, decimation)   (9 = xyz_pos, xzy_vel, xyz_acc)\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 0. Define and Compute usefull variables\n",
    "\n",
    "        # Heuristic TODO Save that on the right place, could also be a RL variable\n",
    "        step_height = 0.05\n",
    "\n",
    "        # Time during wich the leg is in swing.(add small numerical value to denominator to avoid division by 0)\n",
    "        # Shape (batch_size, num_legs)\n",
    "        swing_period = ((1-d) / (f.abs()+1e-10))\n",
    "        half_swing_period = swing_period / 2\n",
    "        time_fac = 1 / ((swing_period.abs()+1e-10) / 2) #bezier_time_factor\n",
    "\n",
    "\n",
    "        # Step 1. Retrieve the three interpolation points : p0, p1, p2 (lift-off, middle point, touch down)\n",
    "\n",
    "        # Retrieve p0 : If c(0)=0 and c(-1)=1 : The leg lift-off -> p0 = p(-1) (value from simulation : the last value where c=1)\n",
    "        # Update only the p0 that are new lift off positions (unsqueeze lifting off -> shape(batc_size, num_legs, 1) to make it compatible for multiplication with p shape)\n",
    "        # p0 shape (batch_size, num_legs, 3) \n",
    "        # TODO Improve this and debug using viz\n",
    "        lifting_off = ((c[:,:,0]==0) * (self.c_prev == 1)).unsqueeze(-1)  \n",
    "        self.p0 = (self.p_lw_sim_prev * lifting_off) + (self.p0 * ~lifting_off)  \n",
    "\n",
    "        # Retrieve p2 : this is simply the foot touch down prior given as input\n",
    "        # p2 shape (batch_size, num_legs, 3) \n",
    "        p2 = p_lw \n",
    "\n",
    "        # Retrieve p1 : (x,y) position are define as the middle point between p0 and p1 (lift-off and touch-down). z is heuristcally define\n",
    "        # p1 shape (batch_size, num_legs, 3)\n",
    "        # TODO Not only choose height as step heigh but use +the terrain height or +the feet height at touch down\n",
    "        p1 = (self.p0[:,:,:2] + p2[:,:,:2]) / 2     # p1(x,y) is in the middle of p0 and p2\n",
    "        p1 = torch.cat((p1, step_height*torch.ones_like(p1[:,:,:1])), dim=2) # Append a third dimension z : defined as step_height\n",
    "\n",
    "        # Step 2. Compute the parameters for the interpolation\n",
    "\n",
    "        # Swing time : reset if lifting off, then increment by one time step (outer loop)  (squeeze lifting_off : (batch_size, num_legs, 1)->(batch_size, num_legs))\n",
    "        # then compute t in [0, Delta_t/2], which would be use for the spline interpolation\n",
    "        # t & swing_time shape (batch_size, num_legs)\n",
    "        self.swing_time = (self.swing_time * ~lifting_off.squeeze(-1)) + self._dt_out\n",
    "        t = self.swing_time % (half_swing_period.abs() + 1e-10)  # Swing time (half) : add small numerical value to avoid nan when % 0\n",
    "\n",
    "        # Compute the a,b,c,d polynimial coefficient for the cubic interpolation S(t) = a*t^3 + b*t^2 + c*t + d\n",
    "        # If swing_time < swing period/2 -> S_0(t) (ie. first interpolation), otherwise -> S_1(t - delta_t/2) (ie. second interpolation)\n",
    "        # cp_x shape (batch_size, num_legs, 3)\n",
    "        is_S0 = (self.swing_time <=  half_swing_period).unsqueeze(-1).expand(*[-1] * len(self.swing_time.shape), 3)  # shape (batch_size, num_legs, 3)\n",
    "        cp1 = (self.p0 * is_S0)                                         + (p1 * ~is_S0)\n",
    "        cp2 = (self.p0 * is_S0)                                         + (torch.cat((p2[:,:,:2], p1[:,:,2:]), dim=2)* ~is_S0)\n",
    "        cp3 = (torch.cat((self.p0[:,:,:2], p1[:,:,2:]), dim=2) * is_S0) + (p2 * ~is_S0)\n",
    "        cp4 = (p1 * is_S0)                                              + (p2 * ~is_S0)\n",
    "\n",
    "        # Step 3. Prepare parameters to compute interpolation trajectory in one operation -> matrix multiplication\n",
    "        \n",
    "        # Generate the time trajectory t -> [t, t + dt, t+ 2*dt,...]\n",
    "        # time_fac, t : shape(batch_size, num_legs) -> unsqueezed(-1) -> Shape (batch_size, num_legs, 1)\n",
    "        # (arrange = [0,1,2,...])*dt.unsqueeze(0).unsqueeze(-1)       -> Shape (1, 1, decimation)\n",
    "        # time traj : Shape (batch_size, num_legs, decimation)\n",
    "        t_traj = (time_fac*t).unsqueeze(-1) + (torch.arange(self._decimation, device=self._device)*self._dt_in).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # Prepare cp_x to be mutltiplied by the time traj :  shape(batch_size, num_leg, 3) -> (batch_size, num_leg, 3, 1)\n",
    "        cp1 = cp1.unsqueeze(-1)\n",
    "        cp2 = cp2.unsqueeze(-1)\n",
    "        cp3 = cp3.unsqueeze(-1)\n",
    "        cp4 = cp4.unsqueeze(-1)\n",
    "\n",
    "        # Prepare time traj to be multplied by cp_x : shape(batch_size, num_leg, decimation) -> (batch_size, num_leg, 1, decimation)\n",
    "        t_traj = t_traj.unsqueeze(2)\n",
    "\n",
    "\n",
    "        # Step 4. Compute the interpolation trajectory\n",
    "        # shape (batch_size, num_legs, 3, decimation)\n",
    "        desired_foot_pos_traj = cp1*(1 - t_traj)**3 + 3*cp2*(t_traj)*(1 - t_traj)**2 + 3*cp3*((t_traj)**2)*(1 - t_traj) + cp4*(t_traj)**3\n",
    "        desired_foot_vel_traj = 3*(cp2 - cp1)*(1 - t_traj)**2 + 6*(cp3 - cp2)*(1 - t_traj)*(t_traj) + 3*(cp4 - cp3)*(t_traj)**2\n",
    "        desired_foot_acc_traj = 6*(1 - t_traj) * (cp3 - 2*cp2 + cp1) + 6 * (t_traj) * (cp4 - 2*cp3 + cp2)\n",
    "\n",
    "        # shape (batch_size, num_legs, 9, decimation) (9 = xyz_pos, xzy_vel, xyz_acc)\n",
    "        pt_b = torch.cat((desired_foot_pos_traj, desired_foot_vel_traj, desired_foot_acc_traj), dim=2)\n",
    "\n",
    "        if(pt_b.isnan().any()):\n",
    "            print('alo')\n",
    "        return pt_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def get_robot_state(self):\n",
    "        \"\"\" Retrieve the Robot states from the simulator\n",
    "\n",
    "        Return :\n",
    "            - p   (torch.Tensor): Feet Position  (latest from sim)      of shape(batch_size, num_legs, 3)\n",
    "            - p_dot (tch.Tensor): Feet velocity  (latest from sim)      of shape(batch_size, num_legs, 3)\n",
    "            - q_dot (tch.Tensor): Joint velocity (latest from sim)      of shape(batch_size, num_legs, num_joints_per_leg)\n",
    "            - jacobian_w  (Tsor): Jacobian -> joint frame to foot frame of shape(batch_size, num_legs, 3, num_joints_per_leg)\n",
    "            - jacobian_dot_w (T): Jacobian derivative (forward euler)   of shape(batch_size, num_legs, 3, num_joints_per_leg)\n",
    "            - mass_matrix (Tsor): Mass Matrix in joint space            of shape(batch_size, num_legs, num_joints_per_leg, num_joints_per_leg)\n",
    "            - h   (torch.Tensor): C(q,q_dot) + G(q) (corr. and grav F.) of shape(batch_size, num_legs, num_joints_per_leg)\n",
    "        \"\"\"\n",
    "\n",
    "        # Retrieve robot base position and orientation in order to compute world->base frame transformation\n",
    "        robot_pos_w = self._asset.data.root_pos_w       # shape (batch_size, 3) (xyz)\n",
    "        robot_orientation_w = self._asset.data.root_quat_w # shape (batch_size, 4) (quaternions)\n",
    "        robot_vel_w = self._asset.data.root_lin_vel_w\n",
    "        # robot_ang_vel_w = self._asset.data.root_ang_vel_w\n",
    "\n",
    "        # Retrieve Feet position in world frame : [num_instances, num_bodies, 3] select right indexes to get \n",
    "        # shape(batch_size, num_legs, 3)\n",
    "        # Finally apply frame transformation to get feet position in body frame\n",
    "        p_w = self._asset.data.body_pos_w[:, self._foot_idx,:]\n",
    "        p_orientation_w = self._asset.data.body_quat_w[:, self._foot_idx,:]\n",
    "        p_b_0, _ = math_utils.subtract_frame_transforms(robot_pos_w, robot_orientation_w, p_w[:,0,:], p_orientation_w[:,0,:])\n",
    "        p_b_1, _ = math_utils.subtract_frame_transforms(robot_pos_w, robot_orientation_w, p_w[:,1,:], p_orientation_w[:,1,:])\n",
    "        p_b_2, _ = math_utils.subtract_frame_transforms(robot_pos_w, robot_orientation_w, p_w[:,2,:], p_orientation_w[:,2,:])\n",
    "        p_b_3, _ = math_utils.subtract_frame_transforms(robot_pos_w, robot_orientation_w, p_w[:,3,:], p_orientation_w[:,3,:])\n",
    "        p_b = torch.cat((p_b_0.unsqueeze(1), p_b_1.unsqueeze(1), p_b_2.unsqueeze(1), p_b_3.unsqueeze(1)), dim=1)\n",
    "\n",
    "        # Retrieve Feet velocity in world frame : [num_instances, num_bodies, 3] select right indexes to get \n",
    "        # shape(batch_size, num_legs, 3)\n",
    "        # Finally apply frame transformation to get feet position in body frame\n",
    "        p_dot_w = self._asset.data.body_lin_vel_w[:, self._foot_idx,:]\n",
    "        # p_dot_orientation_w = self._asset.data.body_ang_vel_w[:, self._foot_idx, :]\n",
    "        p_dot_b_0, _ = math_utils.subtract_frame_transforms(robot_vel_w, robot_orientation_w, p_dot_w[:,0,:], p_orientation_w[:,0,:])\n",
    "        p_dot_b_1, _ = math_utils.subtract_frame_transforms(robot_vel_w, robot_orientation_w, p_dot_w[:,1,:], p_orientation_w[:,1,:])\n",
    "        p_dot_b_2, _ = math_utils.subtract_frame_transforms(robot_vel_w, robot_orientation_w, p_dot_w[:,2,:], p_orientation_w[:,2,:])\n",
    "        p_dot_b_3, _ = math_utils.subtract_frame_transforms(robot_vel_w, robot_orientation_w, p_dot_w[:,3,:], p_orientation_w[:,3,:])\n",
    "        p_dot_b = torch.cat((p_dot_b_0.unsqueeze(1), p_dot_b_1.unsqueeze(1), p_dot_b_2.unsqueeze(1), p_dot_b_3.unsqueeze(1)), dim=1)\n",
    "\n",
    "        # Retrieve Joint velocities [num_instances, num_joints] -> reorganise the view and permute to get the\n",
    "        # shape(batch_size, num_legs, num_joints_per_leg) : This is in joint space, no transformation required\n",
    "        q_dot = self._asset.data.joint_vel.view(-1,self._num_joints_per_leg,self._num_legs).permute(0,2,1)\n",
    "\n",
    "        # Retrieve Jacobian from sim  shape(batch_size, num_legs, 3, num_joints_per_leg) -> see method for implementation\n",
    "        jacobian_w, jacobian_b = self.get_jacobian()\n",
    "\n",
    "        # Compute jacobian derivative, using forward euler. shape(batch_size, num_legs, 3, num_joints_per_leg)\n",
    "        jacobian_dot_w = ((jacobian_w - self.jacobian_prev_w) / self._env.physics_dt)\n",
    "\n",
    "        # Save jacobian for next iteration : required to compute jacobian derivative shape(batch_size, num_legs, 3, num_joints_per_leg)\n",
    "        self.jacobian_prev_w = jacobian_w\n",
    "        \n",
    "        # Retrieve the mass Matrix\n",
    "        # Shape is (batch_size, num_joints, num_joints) (ie. 144 element), we have to extract num leg sub matrices from that to have \n",
    "        # shape (batch_size, num_leg, num_joints_per_leg, num_joints_per_leg) (ie. 36 elements)\n",
    "        # This is done with complex indexing operations\n",
    "        # mass_matrix_full = self._asset.root_physx_view.get_mass_matrices()\n",
    "        # mass_matrix_FL = mass_matrix_full[:,[0,4,8],:][:, [0,4,8]]\n",
    "        joints_idx_tensor = torch.Tensor(self._joints_idx).unsqueeze(2).unsqueeze(3).long() # long to use it to access indexes -> float trow an error\n",
    "        mass_matrix = self._asset.root_physx_view.get_mass_matrices()[:, joints_idx_tensor, joints_idx_tensor.transpose(1,2)].squeeze(-1)\n",
    "        \n",
    "        # Retrieve Corriolis, centrifugial and gravitationnal term\n",
    "        # get_coriolis_and_centrifugal_forces -> (batch_size, num_joints)\n",
    "        # get_generalized_gravity_forces -> (batch_size, num_joints)\n",
    "        # Reshape and tranpose to get the correct shape in correct joint order-> (batch_size, num_legs, num_joints_per_leg)\n",
    "        h = (self._asset.root_physx_view.get_coriolis_and_centrifugal_forces() + self._asset.root_physx_view.get_generalized_gravity_forces()).view(self.num_envs, self._num_joints_per_leg, self._num_legs).permute(0,2,1)\n",
    "\n",
    "        return p_b, p_dot_b, q_dot, jacobian_w, jacobian_dot_w, mass_matrix, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ True,  True, False],\n",
      "         [ True, False, False],\n",
      "         [ True, False,  True],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[False,  True, False],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True, False],\n",
      "         [ True, False, False]]])\n",
      "torch.Size([2, 4, 3])\n",
      "tensor([[ True,  True,  True,  True],\n",
      "        [False,  True,  True,  True]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True],\n",
       "        [False,  True,  True,  True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "c = torch.empty((2,4,3), dtype=torch.bool).bernoulli(0.5)\n",
    "print(c)\n",
    "print(c.shape)\n",
    "\n",
    "print(c[:,:,0])\n",
    "c[:,:,0]==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[ 0,  4,  8],\n",
      "        [ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac = torch.tensor([[0,4,8],[1,5,9],[2,6,10],[3,7,11]])\n",
    "print(jac.shape)\n",
    "print(jac)\n",
    "\n",
    "jac.permute(1,0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "f = torch.tensor([[0,4,8],[1,5,9],[2,6,10],[3,7,11]])\n",
    "print(f.shape)\n",
    "\n",
    "f.shape[1:].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "\n",
      "tensor([[0.5000, 0.0000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.0000, 0.5000, 0.0000]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "phase = torch.tensor([[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0], [0.0,0.0,0.0,0.0]])\n",
    "print(phase)\n",
    "print()\n",
    "\n",
    "env_ids = [0,2]\n",
    "\n",
    "phase[env_ids,:] = torch.zeros_like(phase)[env_ids,:]\n",
    "print(phase)\n",
    "print()\n",
    "\n",
    "# (phase[env_ids,:])[:,(0,2)] = 0.5 # Init phase [0.5, 0, 0.5, 0]\n",
    "phase[env_ids,0] = 0.5 # Init phase [0.5, 0, 0.5, 0]\n",
    "phase[env_ids,2] = 0.5 # Init phase [0.5, 0, 0.5, 0]\n",
    "print(phase)\n",
    "print()\n",
    "\n",
    "# print(phase[env_ids,:2])\n",
    "# print()\n",
    "\n",
    "# phase[:,(0,2)] = 0.5\n",
    "# print(phase)\n",
    "# print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
      "        0.9000, 1.0000, 1.1000])\n",
      "tensor([ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "        False, False])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2000, 0.4000, 0.6000, 0.8000, 1.0000, 0.2000, 0.4000, 0.6000,\n",
       "        0.8000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "T = torch.tensor([[0,4,8],[1,5,9], [2,6,10],[3,7,11]])\n",
    "T.permute(1,0).reshape(12)\n",
    "\n",
    "phase = torch.arange(start=0, end=1.11, step=0.1)\n",
    "print(phase)\n",
    "\n",
    "is_S0 = phase <= 0.5\n",
    "\n",
    "print(is_S0)\n",
    "\n",
    "(2*phase - 1*(~is_S0)).clamp(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1, 22])\n",
      "torch.Size([1, 1, 1, 22])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "full_phase_traj = torch.cat((torch.arange(start=0, end=1.01, step=0.1), torch.arange(start=0, end=1.01, step=0.1))).unsqueeze(0).unsqueeze(1).unsqueeze(2)\n",
    "print(full_phase_traj.shape)\n",
    "is_S0 = (torch.arange(start=0, end=22, step=1) < 11).unsqueeze(0).unsqueeze(1).unsqueeze(2)\n",
    "print(is_S0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0000, -1.0000,  0.0300],\n",
      "         [ 2.0000, -2.0000,  0.0300],\n",
      "         [ 3.0000, -3.0000,  0.0300],\n",
      "         [ 4.0000, -4.0000,  0.0300]],\n",
      "\n",
      "        [[ 1.0000, -1.0000,  0.0300],\n",
      "         [ 2.0000, -2.0000,  0.0300],\n",
      "         [ 3.0000, -3.0000,  0.0300],\n",
      "         [ 4.0000, -4.0000,  0.0300]],\n",
      "\n",
      "        [[ 1.0000, -1.0000,  0.0300],\n",
      "         [ 2.0000, -2.0000,  0.0300],\n",
      "         [ 3.0000, -3.0000,  0.0300],\n",
      "         [ 4.0000, -4.0000,  0.0300]],\n",
      "\n",
      "        [[ 1.0000, -1.0000,  0.0300],\n",
      "         [ 2.0000, -2.0000,  0.0300],\n",
      "         [ 3.0000, -3.0000,  0.0300],\n",
      "         [ 4.0000, -4.0000,  0.0300]]])\n",
      "tensor([[[ 2.0000, -2.0000,  0.0300],\n",
      "         [ 3.0000, -3.0000,  0.0300],\n",
      "         [ 4.0000, -4.0000,  0.0300],\n",
      "         [ 1.0000, -1.0000,  0.0300]],\n",
      "\n",
      "        [[ 2.0000, -2.0000,  0.0300],\n",
      "         [ 3.0000, -3.0000,  0.0300],\n",
      "         [ 4.0000, -4.0000,  0.0300],\n",
      "         [ 1.0000, -1.0000,  0.0300]],\n",
      "\n",
      "        [[ 2.0000, -2.0000,  0.0300],\n",
      "         [ 3.0000, -3.0000,  0.0300],\n",
      "         [ 4.0000, -4.0000,  0.0300],\n",
      "         [ 1.0000, -1.0000,  0.0300]],\n",
      "\n",
      "        [[ 2.0000, -2.0000,  0.0300],\n",
      "         [ 3.0000, -3.0000,  0.0300],\n",
      "         [ 4.0000, -4.0000,  0.0300],\n",
      "         [ 1.0000, -1.0000,  0.0300]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "FOOT_OFFSET = 0.03\n",
    "# Find the corner points of the polygon - provide big values that will be clipped to corresponding bound\n",
    "# p shape(num_corners, 3)\n",
    "p = torch.tensor([[1,-1,FOOT_OFFSET],[2,-2,FOOT_OFFSET],[3,-3,FOOT_OFFSET],[4,-4,FOOT_OFFSET]])\n",
    "\n",
    "# Reshape p to be passed to transform_p_from_rl_to_lw -> (num_corner, num_legs, 3, 1)\n",
    "p = p.unsqueeze(1).expand(4,4,3)\n",
    "\n",
    "p = p.permute(1,0,2)\n",
    "# p[:,:,:] = 2*p[:,:,:]\n",
    "\n",
    "print(p)\n",
    "\n",
    "print(p.roll(-1,dims=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x754e7ac50580>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "T = torch.tensor([[0,1,2,3,4,5,6,7,8],[2,7,11,4,5,6,1,2,3]])\n",
    "\n",
    "bound = [2.0,6.0]\n",
    "T.clamp(bound[0], bound[1])\n",
    "\n",
    "plt.plot(T[0,:])\n",
    "\n",
    "plt.plot((T - T.clamp(bound[0], bound[1]))[0,:])\n",
    "plt.plot(-torch.abs((T - T.clamp(bound[0], bound[1]))[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 56])\n",
      "56\n",
      "\n",
      "4\n",
      "torch.Size([64, 4])\n",
      "4\n",
      "torch.Size([64, 4])\n",
      "12\n",
      "torch.Size([64, 4, 3, 1])\n",
      "36\n",
      "torch.Size([64, 4, 3, 3])\n",
      "\n",
      "4\n",
      "torch.Size([64, 4])\n",
      "4\n",
      "torch.Size([64, 4])\n",
      "12\n",
      "torch.Size([64, 4, 3, 1])\n",
      "36\n",
      "torch.Size([64, 4, 3, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_envs = 64\n",
    "_num_legs = 4\n",
    "_number_predict_step = 1\n",
    "_prevision_horizon = 3\n",
    "device = 'cpu'\n",
    "\n",
    "f = 1*torch.ones(num_envs, _num_legs, device=device)\n",
    "d = 0.55*torch.ones(num_envs, _num_legs, device=device)\n",
    "p_lw = torch.zeros(num_envs, _num_legs, 3, _number_predict_step, device=device)\n",
    "p_rl = torch.zeros(num_envs, _num_legs, 3, _number_predict_step, device=device) # Used to compute penalty term\n",
    "F_lw = torch.zeros(num_envs, _num_legs, 3, _prevision_horizon, device=device)\n",
    "z = [f, d, p_lw, F_lw]\n",
    "\n",
    "actions = torch.randn(num_envs, sum(variable.shape[1:].numel() for variable in z), device=device)\n",
    "print(actions.shape)\n",
    "\n",
    "print(sum(variable.shape[1:].numel() for variable in z)) \n",
    "print()\n",
    "\n",
    "for variable in z:\n",
    "    print(variable.shape[1:].numel())\n",
    "    print(variable.shape)\n",
    "print()\n",
    "\n",
    "f = actions[:, 0 : f.shape[1:].numel()]\n",
    "d = actions[:, f.shape[1:].numel() : f.shape[1:].numel() + d.shape[1:].numel()]\n",
    "p_lw = actions[:, f.shape[1:].numel() + d.shape[1:].numel() : f.shape[1:].numel() + d.shape[1:].numel() + p_lw.shape[1:].numel()].reshape_as(p_lw)\n",
    "F_lw = actions[:, f.shape[1:].numel() + d.shape[1:].numel() + p_lw.shape[1:].numel() : f.shape[1:].numel() + d.shape[1:].numel() + p_lw.shape[1:].numel() + F_lw.shape[1:].numel()].reshape_as(F_lw)\n",
    "\n",
    "z = [f, d, p_lw, F_lw]\n",
    "for variable in z:\n",
    "    print(variable.shape[1:].numel())\n",
    "    print(variable.shape)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "torch.Size([10, 3, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.3365e-01,  9.6838e-01, -1.8004e+00,  3.1203e+00,  1.1875e+00],\n",
       "         [ 1.1013e+00, -5.6833e+00,  1.5057e+00, -3.8912e+00, -2.6385e+00],\n",
       "         [ 9.3424e-01,  9.9264e-01, -2.3082e+00, -1.3657e+00,  6.7267e-01]],\n",
       "\n",
       "        [[-1.9442e-01, -3.4300e-01,  7.8670e-02, -5.7622e-01,  9.1210e-02],\n",
       "         [-5.3612e-01, -2.1279e-01, -2.2476e-01, -1.4254e-01, -2.1596e-03],\n",
       "         [ 3.2512e-02,  1.7837e-01,  2.4883e-01, -2.8350e-01,  5.2160e-01]],\n",
       "\n",
       "        [[-4.2796e-01,  4.9321e+00,  3.3061e+00,  1.8717e+00, -9.5266e-01],\n",
       "         [-1.7079e+00, -7.3135e-01, -1.7175e+00,  1.8330e+00, -2.6230e+00],\n",
       "         [-2.7789e+00,  1.1727e+00,  3.2427e+00, -1.6299e+00,  1.7539e+00]],\n",
       "\n",
       "        [[ 2.5066e+00, -6.2748e+00,  5.5286e+00, -1.2821e+01,  1.4550e-02],\n",
       "         [-5.8101e-01, -1.6196e-01,  1.8136e+00,  8.8238e+00,  1.9647e-01],\n",
       "         [-1.8229e+00,  2.2025e+00,  4.6450e+00,  6.7667e+00,  2.1184e+00]],\n",
       "\n",
       "        [[ 8.8243e-01,  1.2052e-01, -9.6759e-01, -1.8618e-01, -2.2502e-01],\n",
       "         [ 6.0421e-01, -2.1540e-01, -5.2019e-01, -5.1792e-01, -7.7056e-02],\n",
       "         [-3.2260e-02,  5.6294e-01,  3.8231e-01,  5.1246e-01,  3.5319e-02]],\n",
       "\n",
       "        [[ 3.1145e+00, -6.3850e+00,  6.7649e+00,  4.2947e+00,  1.6592e+00],\n",
       "         [-7.5955e+00, -2.0736e-01,  1.2602e+00, -3.2641e+00, -3.5996e+00],\n",
       "         [ 2.0710e+00, -5.1184e+00, -5.2834e+00, -2.1745e+00, -5.7312e-01]],\n",
       "\n",
       "        [[-3.9322e-01, -8.2752e-02,  7.0897e-02,  8.3229e-02,  2.9297e-01],\n",
       "         [-5.1942e-01,  4.4809e-01,  2.2333e-01,  5.9992e-01,  7.0025e-01],\n",
       "         [ 1.2154e-01, -3.6068e-01, -1.2098e-01, -3.0937e-01, -4.3617e-01]],\n",
       "\n",
       "        [[-4.5236e+00,  1.4031e+00,  3.2954e+00,  3.1699e-01,  4.0366e+00],\n",
       "         [-3.6423e+00, -1.7729e+00, -1.6050e-01, -4.3464e+00,  3.1035e+00],\n",
       "         [-1.7457e+00, -1.5222e+00,  3.2360e-01,  1.0012e+00,  1.5124e+00]],\n",
       "\n",
       "        [[-5.4073e-03,  9.4162e-03, -5.6676e-03,  1.5927e-02, -1.6696e-02],\n",
       "         [-4.1429e-03, -1.5816e-02,  4.4257e-03, -1.7841e-04, -3.6205e-03],\n",
       "         [-8.7526e-03, -1.2371e-03, -1.7579e-03, -2.1407e-03,  2.0334e-02]],\n",
       "\n",
       "        [[-1.6593e+00, -4.1087e-01,  5.1033e-01, -1.0704e+00, -3.6579e-01],\n",
       "         [-3.1808e+00, -4.3288e+00, -4.5706e+00, -3.3593e+00, -1.7024e+00],\n",
       "         [-1.6746e-01,  7.2090e-01,  5.6026e-01, -3.3042e+00,  3.5694e+00]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(10,4)\n",
    "b = torch.sum(a, dim=1)\n",
    "c = torch.randn(10,3,5)\n",
    "print(b.shape)\n",
    "print(c.shape)\n",
    "b.unsqueeze(-1).unsqueeze(-1)*c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example dimensions\n",
    "b = 2\n",
    "n = 3\n",
    "\n",
    "# Example tensors p and p_prev of dimension (b, n, 3)\n",
    "p = torch.randn(b, n, 3)\n",
    "p_prev = torch.randn(b, n, 3)\n",
    "\n",
    "# Calculate the squared difference and sum along the last dimension\n",
    "squared_difference_sum = torch.sum(torch.square(p - p_prev), dim=-1)\n",
    "\n",
    "# Verify the output shape\n",
    "print(\"Output shape:\", squared_difference_sum.shape)  # Output: (b,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4])\n",
      "tensor([0.2023, 0.0271, 0.8369, 0.7345, 0.4740, 0.3796, 0.0417, 0.9282, 0.0021,\n",
      "        0.3301, 0.4110, 0.2978, 0.8927, 0.6978, 0.5533, 0.6596, 0.4820, 0.2477])\n",
      "tensor([ 4, 15, 11, 17])\n",
      "tensor([0.4740, 0.6596, 0.2978, 0.2477])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example usage\n",
    "batch_size = 10\n",
    "grid_size = 18\n",
    "n = 4\n",
    "\n",
    "# Dummy sensor_data and index tensors\n",
    "sensor_data = torch.rand(batch_size, grid_size, 3)\n",
    "index = torch.randint(0, grid_size, (batch_size, n))\n",
    "\n",
    "# Retrieve data in a single flow using advanced indexing\n",
    "retrieved_data = sensor_data[torch.arange(batch_size).unsqueeze(1), index, 2]\n",
    "\n",
    "print(retrieved_data.shape)  # Output: torch.Size([2, 3, 3])\n",
    "\n",
    "torch.arange(batch_size).unsqueeze(1)\n",
    "index\n",
    "\n",
    "print(sensor_data[2,:,2])\n",
    "print(index[2,:])\n",
    "print(retrieved_data[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0059])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.empty(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not all are real, there is a nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0],\n",
       "        [3514,   17,    2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch.distributions.constraints import real\n",
    "\n",
    "a = torch.randn((4096,183,3))\n",
    "\n",
    "a[1,2,:18]\n",
    "\n",
    "a[0,0,0] = torch.nan\n",
    "a[3514, 17, 2] = torch.nan\n",
    "\n",
    "torch.isreal(a).all()\n",
    "\n",
    "(a == a) # Fail for Nan\n",
    "\n",
    "if not real.check(a).all() :\n",
    "    print('not all are real, there is a nan')\n",
    "\n",
    "torch.nonzero(~real.check(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 3])\n",
      "torch.Size([16, 4, 2])\n",
      "10 tensor(10.)\n",
      "10 tensor(10.)\n",
      "-10 tensor(-10.)\n",
      "0 tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "F = torch.randn((16,4,3))\n",
    "\n",
    "print(F[:,:,:].shape)\n",
    "print(F[:,:,:2].shape)\n",
    "\n",
    "F[0,0,0] = 10\n",
    "print('10',F[0,0,0])\n",
    "\n",
    "F = F.clamp(min=0)\n",
    "print('10',F[0,0,0])\n",
    "\n",
    "F[0,0,0] = -10\n",
    "print('-10',F[0,0,0])\n",
    "\n",
    "F = F.clamp(min=0)\n",
    "print('0',F[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.randint(0, 1, (20,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "# from __future__ import print_function\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataloader import ObservationActionDataset, ChunkedObservationActionDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "# dataset = ChunkedObservationActionDataset('dataset/aliengo_model_based_speed/mcQueenOne/training_data_chunk_*.pt')\n",
    "dataset = ObservationActionDataset('dataset/aliengo_model_based_speed/mcQueenFour/training_data.pt')\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "# Define model\n",
    "class Model1(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model1, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.lin1 = nn.Linear(input_size, 512)\n",
    "        self.lin2 = nn.Linear(512, 256)\n",
    "        self.lin3 = nn.Linear(256, 128)\n",
    "        self.lin4 = nn.Linear(128, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.lin2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.lin3(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.lin4(x)\n",
    "        return x\n",
    "\n",
    "# Example model definition\n",
    "input_size = dataset.observations.shape[-1]\n",
    "output_size = dataset.actions.shape[-1]\n",
    "model = Model(input_size, output_size).cuda()\n",
    "\n",
    "print('Input  Size : ', dataset.observations.shape)\n",
    "print('Output Size : ', dataset.actions.shape)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for obs_batch, action_batch in dataloader:\n",
    "        obs_batch, action_batch = obs_batch.cuda(), action_batch.cuda()  # Move to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(obs_batch)\n",
    "        loss = criterion(outputs, action_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "print('Training completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for the first approach (rand_like and comparison): 0.00036716461181640625\n",
      "Time for the second approach (bernoulli and full_like): 0.0001862049102783203\n",
      "tensor([[[0., 0., 1.,  ..., 0., 1., 0.],\n",
      "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 1., 1.,  ..., 1., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 0.,  ..., 1., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [1., 0., 0.,  ..., 0., 1., 1.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [1., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 1.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "         [1., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [1., 1., 0.,  ..., 1., 0., 1.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Assuming B is your input tensor\n",
    "B = torch.empty(1000,1000,100)\n",
    "\n",
    "# Timing the first approach\n",
    "start_time = time.time()\n",
    "A1 = (torch.rand_like(B, device='cuda') > 0.75).float()\n",
    "time1 = time.time() - start_time\n",
    "\n",
    "# Timing the second approach\n",
    "start_time = time.time()\n",
    "A2 = torch.bernoulli(torch.full_like(B, 0.25, device='cuda'))\n",
    "time2 = time.time() - start_time\n",
    "\n",
    "print(\"Time for the first approach (rand_like and comparison):\", time1)\n",
    "print(\"Time for the second approach (bernoulli and full_like):\", time2)\n",
    "\n",
    "print(A1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for clamp_max: 7.128642320632935\n",
      "Time for torch.min: 7.307240962982178\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Example tensor F and parameters\n",
    "F = torch.rand(1000, 1000, 3, 10, device='cuda')  # Change dimensions as needed\n",
    "alpha = torch.tensor(0.5, device='cuda')\n",
    "F_xy_max = torch.rand(1000,1000,10, device='cuda')\n",
    "iter=10000\n",
    "\n",
    "# Measure time for clamp_max\n",
    "start_time = time.time()\n",
    "for _ in range(iter):\n",
    "    F_x_clipped_1 = F[:,:,0,:].clamp_max(torch.cos(alpha) * F_xy_max)\n",
    "    alpha = torch.rand_like(alpha)\n",
    "time_clamp_max = time.time() - start_time\n",
    "\n",
    "# Measure time for torch.min\n",
    "start_time = time.time()\n",
    "for _ in range(iter):\n",
    "    F_x_clipped_2 = torch.min(F[:,:,0,:], torch.cos(alpha) * F_xy_max)\n",
    "    alpha = torch.rand_like(alpha)\n",
    "time_torch_min = time.time() - start_time\n",
    "\n",
    "print(\"Time for clamp_max:\", time_clamp_max)\n",
    "print(\"Time for torch.min:\", time_torch_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original implementation time: 0.036420583724975586\n",
      "Two-step implementation time: 0.05660271644592285\n",
      "Indexing implementation time: 0.084747314453125\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "# Define the functions\n",
    "def compute_tracking_error_original(target_height, robot_height, upper_bound, lower_bound):\n",
    "    raw_error = target_height - robot_height\n",
    "    tracking_error = torch.where(\n",
    "        robot_height > target_height + upper_bound,\n",
    "        raw_error - upper_bound,\n",
    "        torch.where(\n",
    "            robot_height < target_height - lower_bound,\n",
    "            raw_error + lower_bound,\n",
    "            torch.zeros_like(raw_error)\n",
    "        )\n",
    "    )\n",
    "    return tracking_error\n",
    "\n",
    "def compute_tracking_error_two_step(target_height, robot_height, upper_bound, lower_bound):\n",
    "    raw_error = target_height - robot_height\n",
    "    upper_bound_error = torch.where(robot_height > target_height + upper_bound, raw_error - upper_bound, raw_error)\n",
    "    tracking_error = torch.where(robot_height < target_height - lower_bound, raw_error + lower_bound, upper_bound_error)\n",
    "    tracking_error = torch.where((robot_height >= target_height - lower_bound) & (robot_height <= target_height + upper_bound), torch.zeros_like(tracking_error), tracking_error)\n",
    "    return tracking_error\n",
    "\n",
    "def compute_tracking_error_indexing(target_height, robot_height, upper_bound, lower_bound):\n",
    "    raw_error = target_height - robot_height\n",
    "    tracking_error = raw_error.clone()\n",
    "    tracking_error[robot_height > target_height + upper_bound] -= upper_bound\n",
    "    tracking_error[robot_height < target_height - lower_bound] += lower_bound\n",
    "    within_bounds = (robot_height >= target_height - lower_bound) & (robot_height <= target_height + upper_bound)\n",
    "    tracking_error[within_bounds] = 0\n",
    "    return tracking_error\n",
    "\n",
    "# Initialize tensors\n",
    "batch_size = 4096\n",
    "num=1000\n",
    "target_height = torch.tensor([10.0] * batch_size, device=device)\n",
    "robot_height = torch.tensor([8.0] * batch_size, device=device)\n",
    "upper_bound = torch.tensor([2.0], device=device)\n",
    "lower_bound = torch.tensor([2.0], device=device)\n",
    "\n",
    "# Benchmark original\n",
    "start_time = time.time()\n",
    "for i in range(num): tracking_error1 = compute_tracking_error_original(target_height, robot_height, upper_bound, lower_bound)\n",
    "end_time = time.time()\n",
    "print(\"Original implementation time:\", end_time - start_time)\n",
    "\n",
    "# Benchmark two-step\n",
    "start_time = time.time()\n",
    "for i in range(num): tracking_error2 = compute_tracking_error_two_step(target_height, robot_height, upper_bound, lower_bound)\n",
    "end_time = time.time()\n",
    "print(\"Two-step implementation time:\", end_time - start_time)\n",
    "\n",
    "# Benchmark indexing\n",
    "start_time = time.time()\n",
    "for i in range(num): tracking_error3 = compute_tracking_error_indexing(target_height, robot_height, upper_bound, lower_bound)\n",
    "end_time = time.time()\n",
    "print(\"Indexing implementation time:\", end_time - start_time)\n",
    "\n",
    "print(((tracking_error1-tracking_error2) > 1e-10).any())\n",
    "print(((tracking_error1-tracking_error3) > 1e-10).any())\n",
    "print(((tracking_error2-tracking_error3) > 1e-10).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, -0.1000,  0.1000, -0.2000,  0.2000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000, -0.1000,  0.1000])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "height_bound = (-0.1, +0.1)\n",
    "\n",
    "target_height = torch.tensor((0.5, 0.5, 0.5, 0.5, 0.5))\n",
    "robot_height_prop = torch.tensor((0.5, 0.4, 0.6, 0.3, 0.7))\n",
    "\n",
    "\n",
    "# Compute the tracking error\n",
    "tracking_error = robot_height_prop - target_height\n",
    "print(tracking_error)\n",
    "# If tolerance bound are provided adjusted error with bounds\n",
    "if height_bound is not None :\n",
    "\n",
    "    tracking_error = torch.where(\n",
    "        robot_height_prop > target_height + height_bound[1],\n",
    "        tracking_error - height_bound[1],\n",
    "        torch.where(\n",
    "            robot_height_prop < target_height + height_bound[0],\n",
    "            tracking_error - height_bound[0],\n",
    "            torch.zeros_like(tracking_error)\n",
    "        )\n",
    "    )\n",
    "\n",
    "tracking_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full pairwise distances time: 0.003140 seconds\n",
      "Optimized upper triangular distances time: 0.001984 seconds\n",
      "Are the results equivalent? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.9345, 0.5352, 0.7688, 0.4836, 0.6719, 0.7495])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# Example tensor (batch, legs, 2)\n",
    "batch = 40960\n",
    "legs = 4\n",
    "foot_xy_pos = torch.rand((batch, legs, 2))\n",
    "\n",
    "# Full pairwise distance computation\n",
    "def full_pairwise_distances(foot_xy_pos):\n",
    "    foot_exp1 = foot_xy_pos.unsqueeze(2)\n",
    "    foot_exp2 = foot_xy_pos.unsqueeze(1)\n",
    "    diffs = foot_exp1 - foot_exp2\n",
    "    distances = torch.norm(diffs, dim=-1)\n",
    "    upper_triangle_distances = distances.triu(diagonal=1)\n",
    "    return upper_triangle_distances\n",
    "\n",
    "# Optimized upper triangular distance computation\n",
    "def optimized_upper_triangular_distances(foot_xy_pos):\n",
    "    indices = list(itertools.combinations(range(legs), 2))\n",
    "    distances = []\n",
    "    for i, j in indices:\n",
    "        diff = foot_xy_pos[:, i, :] - foot_xy_pos[:, j, :]\n",
    "        dist = torch.norm(diff, dim=1)\n",
    "        distances.append(dist)\n",
    "    distances = torch.stack(distances, dim=1)\n",
    "    return distances\n",
    "\n",
    "# Benchmarking function\n",
    "def benchmark(func, foot_xy_pos, iterations=1000):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        result = func(foot_xy_pos)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time, result\n",
    "\n",
    "# Run benchmarks\n",
    "iterations = 1\n",
    "time_full, result_full = benchmark(full_pairwise_distances, foot_xy_pos, iterations)\n",
    "time_optimized, result_optimized = benchmark(optimized_upper_triangular_distances, foot_xy_pos, iterations)\n",
    "\n",
    "# Print results\n",
    "print(f\"Full pairwise distances time: {time_full:.6f} seconds\")\n",
    "print(f\"Optimized upper triangular distances time: {time_optimized:.6f} seconds\")\n",
    "\n",
    "# Validate that results are equivalent\n",
    "# Extract the upper triangular part (excluding the diagonal) from the full pairwise distances\n",
    "upper_triangle_indices = torch.triu_indices(legs, legs, 1)\n",
    "result_full_upper = result_full[:, upper_triangle_indices[0], upper_triangle_indices[1]]\n",
    "print(f\"Are the results equivalent? {torch.allclose(result_full_upper, result_optimized)}\")\n",
    "\n",
    "result_optimized[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "phase = torch.tensor((0.1,0.2,0.3,0.4))\n",
    "f_samples = torch.rand(3,4)\n",
    "dt=0.1\n",
    "time_horizon=5\n",
    "\n",
    "#            (1,4,1)                  (3,4,1)                    (1,1,5)\n",
    "new_phases = phase.unsqueeze(0).unsqueeze(-1) + (f_samples.unsqueeze(-1) * torch.linspace(start=1, end=time_horizon, steps=time_horizon).unsqueeze(0).unsqueeze(1)*dt)\n",
    "\n",
    "# phase.unsqueeze(-1) + torch.linspace(start=1, end=time_horizon, steps=time_horizon)\n",
    "\n",
    "(f_samples.unsqueeze(-1) * torch.linspace(start=1, end=time_horizon, steps=time_horizon).unsqueeze(0).unsqueeze(1)*dt).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])\n"
     ]
    }
   ],
   "source": [
    "a=torch.linspace(start=1, end=12, steps=12)\n",
    "print(a)\n",
    "\n",
    "b=a.view(4,3)\n",
    "print(b)\n",
    "\n",
    "c=b.flatten(0,1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0654, 0.1308, 0.1962, 0.2616])\n",
      "torch.Size([1])\n",
      "torch.Size([])\n",
      "tensor([0.2164, 0.2818, 0.3473, 0.4127, 0.4781])\n"
     ]
    }
   ],
   "source": [
    "com_pose_lw = torch.rand(3)\n",
    "com_pose_ref_lw = torch.rand(3,5)\n",
    "speed_command = torch.rand(3)\n",
    "time_horizon = 5\n",
    "dt = 0.1\n",
    "\n",
    "com_pose_ref_lw[2] =  com_pose_lw[2] + (torch.arange(time_horizon) * (dt * speed_command[2]))\n",
    "# com_pose_ref_lw[2] =  com_pose_lw[2] + (torch.arange(time_horizon) * (dt * speed_command[2]))\n",
    "\n",
    "print((torch.arange(time_horizon) * (dt * speed_command[2])))\n",
    "print(com_pose_lw[2].unsqueeze(-1).shape)\n",
    "print(com_pose_lw[2].shape)\n",
    "print(com_pose_ref_lw[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      "\n",
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      "\n",
      "[0.19868964 0.4115519  0.6287666  0.04808122]\n",
      "[0.19868964 0.4115519  0.6287666  0.04808122]\n",
      "[0.19868964 0.4115519  0.6287666  0.04808122]\n",
      "[0.19868964 0.4115519  0.6287666  0.04808122]\n",
      "[0.19868964 0.4115519  0.6287666  0.04808122]\n",
      "[0.19868964 0.4115519  0.6287666  0.04808122]\n",
      "Execution time Jitted Normal spline: 0.463567 seconds\n",
      "Execution time  Jitted Fast  spline: 0.455257 seconds\n",
      "Execution time  Jitted Fast  spline: 0.453715 seconds\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import time\n",
    "\n",
    "def compute_cubic_spline(parameters, step, horizon_leg):\n",
    "    \"\"\" Given a set of parameters, return the spline. \n",
    "    \n",
    "    Args :\n",
    "        \n",
    "    Returns : \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #tau = step/(self.horizon-1)\n",
    "    tau = step/(horizon_leg)\n",
    "    q = (tau - 0.0)/(1.0-0.0)\n",
    "    \n",
    "    phi = (1./2.)*(((parameters[2] - parameters[1])/0.5) + ((parameters[1] - parameters[0])/0.5))\n",
    "    phi_next = (1./2.)*(((parameters[3] - parameters[2])/0.5) + ((parameters[2] - parameters[1])/0.5))\n",
    "    \n",
    "    a_x = 2*q*q*q - 3*q*q + 1\n",
    "    b_x = (q*q*q - 2*q*q + q)*0.5\n",
    "    c_x = -2*q*q*q + 3*q*q\n",
    "    d_x = (q*q*q - q*q)*0.5\n",
    "    f_x = a_x*parameters[1] + b_x*phi + c_x*parameters[2] + d_x*phi_next\n",
    "\n",
    "    phi = (1./2.)*(((parameters[6] - parameters[5])/0.5) + ((parameters[5] - parameters[4])/0.5))\n",
    "    phi_next = (1./2.)*(((parameters[7] - parameters[6])/0.5) + ((parameters[6] - parameters[5])/0.5))\n",
    "    \n",
    "    a_y = 2*q*q*q - 3*q*q + 1\n",
    "    b_y = (q*q*q - 2*q*q + q)*0.5\n",
    "    c_y = -2*q*q*q + 3*q*q\n",
    "    d_y = (q*q*q - q*q)*0.5\n",
    "    f_y = a_y*parameters[5] + b_y*phi + c_y*parameters[6] + d_y*phi_next\n",
    "\n",
    "\n",
    "    phi = (1./2.)*(((parameters[10] - parameters[9])/0.5) + ((parameters[9] - parameters[8])/0.5))\n",
    "    phi_next = (1./2.)*(((parameters[11] - parameters[10])/0.5) + ((parameters[10] - parameters[9])/0.5))\n",
    "    \n",
    "    a_z = 2*q*q*q - 3*q*q + 1\n",
    "    b_z = (q*q*q - 2*q*q + q)*0.5\n",
    "    c_z = -2*q*q*q + 3*q*q\n",
    "    d_z = (q*q*q - q*q)*0.5\n",
    "    f_z = a_z*parameters[9] + b_z*phi + c_z*parameters[10] + d_z*phi_next\n",
    "    \n",
    "    # return f_x, f_y, f_z\n",
    "    return f_z   \n",
    "\n",
    "def compute_fast_cubic_spline(parameters, step, horizon_leg):\n",
    "    \"\"\" Given a set of parameters, return the spline. \n",
    "    \n",
    "    Args :\n",
    "        \n",
    "    Returns : \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #tau = step/(self.horizon-1)\n",
    "    tau = step/(horizon_leg)\n",
    "    q = (tau - 0.0)/(1.0-0.0)\n",
    "    q2 = q*q\n",
    "    q3 = q2*q\n",
    "    \n",
    "    phi = (1./2.)*(((parameters[2] - parameters[1])/0.5) + ((parameters[1] - parameters[0])/0.5))\n",
    "    phi_next = (1./2.)*(((parameters[3] - parameters[2])/0.5) + ((parameters[2] - parameters[1])/0.5))\n",
    "    \n",
    "    a_x = 2*q3 - 3*q2 + 1\n",
    "    b_x = (q3 - 2*q2 + q)*0.5\n",
    "    c_x = -2*q3 + 3*q2\n",
    "    d_x = (q3 - q2)*0.5\n",
    "    f_x = a_x*parameters[1] + b_x*phi + c_x*parameters[2] + d_x*phi_next\n",
    "\n",
    "    phi = (1./2.)*(((parameters[6] - parameters[5])/0.5) + ((parameters[5] - parameters[4])/0.5))\n",
    "    phi_next = (1./2.)*(((parameters[7] - parameters[6])/0.5) + ((parameters[6] - parameters[5])/0.5))\n",
    "    \n",
    "    a_y = 2*q3 - 3*q2 + 1\n",
    "    b_y = (q3 - 2*q2 + q)*0.5\n",
    "    c_y = -2*q3 + 3*q2\n",
    "    d_y = (q3 - q2)*0.5\n",
    "    f_y = a_y*parameters[5] + b_y*phi + c_y*parameters[6] + d_y*phi_next\n",
    "\n",
    "\n",
    "    phi = (1./2.)*(((parameters[10] - parameters[9])/0.5) + ((parameters[9] - parameters[8])/0.5))\n",
    "    phi_next = (1./2.)*(((parameters[11] - parameters[10])/0.5) + ((parameters[10] - parameters[9])/0.5))\n",
    "    \n",
    "    a_z = 2*q3 - 3*q2 + 1\n",
    "    b_z = (q3 - 2*q2 + q)*0.5\n",
    "    c_z = -2*q3 + 3*q2\n",
    "    d_z = (q3 - q2)*0.5\n",
    "    f_z = a_z*parameters[9] + b_z*phi + c_z*parameters[10] + d_z*phi_next\n",
    "    \n",
    "    # return f_x, f_y, f_z  \n",
    "    return f_z\n",
    "\n",
    "def compute_very_fast_cubic_spline(parameters, step, horizon):\n",
    "    \"\"\" Given a set of spline parameters, and the point in the trajectory return the function value \n",
    "    \n",
    "    Args :\n",
    "        parameters (jnp.array): of shape(TODO)\n",
    "        step             (int): The point in the curve in [0, horizon]\n",
    "        horizon          (int): The length of the curve\n",
    "        \n",
    "    Returns : \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Find the point in the curve q in [0,1]\n",
    "    tau = step/(horizon)        \n",
    "    q = (tau - 0.0)/(1.0-0.0)\n",
    "    q2 = q*q\n",
    "    q3 = q2*q\n",
    "    \n",
    "    # Compute the spline interpolation parameters\n",
    "    a = 2*q3 - 3*q2 + 1\n",
    "    b = (q3 - 2*q2 + q)*0.5\n",
    "    c = -2*q3 + 3*q2\n",
    "    d = (q3 - q2)*0.5\n",
    "\n",
    "    # Compute the phi parameters\n",
    "    phi_x = (1./2.)*(((parameters[2] - parameters[1])/0.5) + ((parameters[1] - parameters[0])/0.5))\n",
    "    phi_next_x = (1./2.)*(((parameters[3] - parameters[2])/0.5) + ((parameters[2] - parameters[1])/0.5))\n",
    "\n",
    "    phi_y = (1./2.)*(((parameters[6] - parameters[5])/0.5) + ((parameters[5] - parameters[4])/0.5))\n",
    "    phi_next_y = (1./2.)*(((parameters[7] - parameters[6])/0.5) + ((parameters[6] - parameters[5])/0.5))\n",
    "\n",
    "    phi_z = (1./2.)*(((parameters[10] - parameters[9])/0.5) + ((parameters[9] - parameters[8])/0.5))\n",
    "    phi_next_z = (1./2.)*(((parameters[11] - parameters[10])/0.5) + ((parameters[10] - parameters[9])/0.5))\n",
    "\n",
    "    # Compute the function value f(x)\n",
    "    f_x = a*parameters[1] + b*phi_x + c*parameters[2]  + d*phi_next_x\n",
    "    f_y = a*parameters[5] + b*phi_y + c*parameters[6]  + d*phi_next_y\n",
    "    f_z = a*parameters[9] + b*phi_z + c*parameters[10] + d*phi_next_z\n",
    "    \n",
    "    return f_z  \n",
    "\n",
    "datatype = 'float32'\n",
    "device = jax.devices('gpu')[0]\n",
    "key = random.PRNGKey(0)\n",
    "iter=10000\n",
    "\n",
    "# parameters = jnp.array((1.0, 1.0, 0.0), dtype=datatype)\n",
    "parameters = random.uniform(key, (1000000, 4), dtype=datatype)\n",
    "step = 3\n",
    "horizon_leg = 10\n",
    "\n",
    "print(type(parameters),'\\n')\n",
    "print(type(compute_cubic_spline(parameters, step, horizon_leg)),'\\n')\n",
    "\n",
    "print(compute_cubic_spline(parameters, step, horizon_leg))\n",
    "print(compute_fast_cubic_spline(parameters, step, horizon_leg))\n",
    "print(compute_very_fast_cubic_spline(parameters, step, horizon_leg))\n",
    "\n",
    "jitted_compute_cubic_spline = jax.jit(compute_cubic_spline, device=device)\n",
    "jitted_compute_fast_cubic_spline = jax.jit(compute_fast_cubic_spline, device=device)\n",
    "jitted_compute_very_fast_cubic_spline = jax.jit(compute_very_fast_cubic_spline, device=device)\n",
    "\n",
    "print(jitted_compute_cubic_spline(parameters, step, horizon_leg))\n",
    "print(jitted_compute_fast_cubic_spline(parameters, step, horizon_leg))\n",
    "print(jitted_compute_very_fast_cubic_spline(parameters, step, horizon_leg))\n",
    "\n",
    "\n",
    "# # Measure execution time\n",
    "# start_time = time.time()\n",
    "# for i in range(iter):\n",
    "#     result = compute_cubic_spline(parameters, step, horizon_leg)\n",
    "# end_time = time.time()\n",
    "\n",
    "# print(f\"Execution time Normal spline: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# # Measure execution time\n",
    "# start_time = time.time()\n",
    "# for i in range(iter):\n",
    "#     result = compute_fast_cubic_spline(parameters, step, horizon_leg)\n",
    "# end_time = time.time()\n",
    "\n",
    "# print(f\"Execution time  Fast  spline: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# Measure execution time\n",
    "start_time = time.time()\n",
    "for i in range(iter):\n",
    "    result = jitted_compute_cubic_spline(parameters, step, horizon_leg)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Execution time Jitted Normal spline: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# Measure execution time\n",
    "start_time = time.time()\n",
    "for i in range(iter):\n",
    "    result = jitted_compute_fast_cubic_spline(parameters, step, horizon_leg)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Execution time  Jitted Fast  spline: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# Measure execution time\n",
    "start_time = time.time()\n",
    "for i in range(iter):\n",
    "    result = jitted_compute_very_fast_cubic_spline(parameters, step, horizon_leg)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Execution time  Jitted Fast  spline: {end_time - start_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2])\n",
      "tensor([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "x = torch.arange(12)\n",
    "f_param = 4\n",
    "\n",
    "print(x)\n",
    "print(x//f_param)\n",
    "print(x%f_param)\n",
    "\n",
    "y = x - ((x%f_param)*(x//f_param))\n",
    "# y = x - ((x%f_param)*(f_param)*(x//f_param))\n",
    "# y = x - ((f_param)*(x//f_param))\n",
    "\n",
    "y = x - ((x-f_param) * (x >= f_param))\n",
    "\n",
    "plt.plot(y)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time    jitted_index_func  : 0.037708 seconds\n",
      "Execution time jitted_index_fast_func: 0.038042 seconds\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def index_func(f_param, x):\n",
    "    return x - ((x-f_param) * (x >= f_param))\n",
    "\n",
    "def index_fast_func(f_param, x):\n",
    "    return jnp.minimum(x, f_param) \n",
    "\n",
    "\n",
    "datatype = 'float32'\n",
    "device = jax.devices('gpu')[0]\n",
    "key = random.PRNGKey(0)\n",
    "f_param = 4\n",
    "iter=1000\n",
    "\n",
    "# parameters = jnp.array((1.0, 1.0, 0.0), dtype=datatype)\n",
    "x = 10*random.uniform(key, (1000000,1), dtype=datatype)\n",
    "\n",
    "y = index_func(f_param, x)\n",
    "\n",
    "# plt.scatter(x,y)\n",
    "# plt.show()\n",
    "\n",
    "jitted_index_func = jax.jit(index_func, device=device)\n",
    "jitted_index_fast_func = jax.jit(index_fast_func, device=device)\n",
    "\n",
    "jitted_index_func(f_param, x)\n",
    "jitted_index_fast_func(f_param, x)\n",
    "\n",
    "# Measure execution time\n",
    "start_time = time.time()\n",
    "for i in range(iter):\n",
    "    result = jitted_index_func(f_param, x)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time    jitted_index_func  : {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# Measure execution time\n",
    "start_time = time.time()\n",
    "for i in range(iter):\n",
    "    result = jitted_index_fast_func(f_param, x)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time jitted_index_fast_func: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# plt.scatter(x,result)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]\n",
      "[0 1 0 1]\n",
      "<class 'jaxlib.xla_extension.DeviceArray'>\n",
      "(12,)\n",
      "float32\n",
      "12\n",
      "1\n",
      "[ 2.  5.  8. 11.]\n",
      "\n",
      "alpha        [1.5707964  0.9272952  0.86217004 0.8379811 ]\n",
      "F_xy         [ 1.        5.        9.219544 13.453624]\n",
      "F_xy_max     [1.1  2.75 4.4  6.05]\n",
      "F_xy_clamped [1.   2.75 4.4  6.05]\n",
      "F_z          [ 2.  5.  8. 11.]\n",
      "F_x_clamped  [-4.3711388e-08  1.6500001e+00  2.8634822e+00  4.0472374e+00]\n",
      "F_clamped    [-4.3711388e-08  1.0000000e+00  2.0000000e+00  1.6500001e+00\n",
      "  2.2000000e+00  5.0000000e+00  2.8634822e+00  3.3407292e+00\n",
      "  8.0000000e+00  4.0472374e+00  4.4969296e+00  1.1000000e+01]\n",
      "F_clamped    [-4.3711388e-08  1.0000000e+00  2.0000000e+00  1.6500001e+00\n",
      "  2.2000000e+00  5.0000000e+00  2.8634822e+00  3.3407292e+00\n",
      "  8.0000000e+00  4.0472374e+00  4.4969296e+00  1.1000000e+01]\n",
      "\n",
      "[-0.         0.         0.         1.6500001  2.2        5.\n",
      "  0.         0.         0.         4.0472374  4.4969296 11.       ]\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "F_x_lw = jnp.float32(12.0) \n",
    "\n",
    "F = jnp.arange(12,dtype=jnp.float32)\n",
    "every_third_element = F[2::3]\n",
    "c = jnp.array([0, 1] * 2, dtype=jnp.int32)\n",
    "\n",
    "\n",
    "print(F)\n",
    "print(c)\n",
    "print(type(F))\n",
    "print(F.shape)\n",
    "print(F.dtype)\n",
    "print(F.size)\n",
    "print(F.ndim)\n",
    "print(every_third_element)\n",
    "print()\n",
    "\n",
    "F_clamped = enforce_force_constraints_new(F=F, c=c)\n",
    "print()\n",
    "print(F_clamped)\n",
    "print(F_clamped.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_force_constraints_new( F: jnp.array, c: jnp.array) -> jnp.array:\n",
    "    \"\"\" Given raw GRFs in local world frame and the contact sequence, return the GRF clamped by the friction cone\n",
    "    and set to zero if not in contact\n",
    "    \n",
    "    Args :\n",
    "        F (jnp.array): Ground Reaction forces samples                    of shape(num_legs*3)\n",
    "        c    (jnp.array): contact sequence samples                       of shape(num_legs)\n",
    "        \n",
    "    Return\n",
    "        F_lw (jnp.array): Clamped ground reaction forces                 of shape(num_legs*3)\"\"\"\n",
    "\n",
    "    # --- Step 1 : Enforce the friction cone constraints\n",
    "    # Retrieve Force component\n",
    "    F_x = F[0::3]  # x components: elements 0, 3, 6, 9\n",
    "    F_y = F[1::3]  # y components: elements 1, 4, 7, 10\n",
    "    F_z = F[2::3]  # z components: elements 2, 5, 8, 11\n",
    "    \n",
    "\n",
    "    # Compute the maximum Force in the xz plane\n",
    "    F_xy_max = 0.55 * F_z\n",
    "\n",
    "    # Compute the actual force in the xy plane\n",
    "    F_xy = jnp.sqrt(F_x**2 + F_y**2)\n",
    "\n",
    "    # Compute the angle in the xy plane of the Force\n",
    "    alpha = jnp.arccos(F_x / F_xy)\n",
    "    print('alpha       ',alpha)\n",
    "\n",
    "    # Apply the constraint in the xy plane\n",
    "    F_xy_clamped = jnp.minimum(F_xy, F_xy_max)\n",
    "\n",
    "    print('F_xy        ',F_xy)\n",
    "    print('F_xy_max    ',F_xy_max)\n",
    "    print('F_xy_clamped',F_xy_clamped)\n",
    "    print('F_z         ', F_z)\n",
    "\n",
    "    # Project these clamped forces in the xy plane back as x,y component\n",
    "    F_x_clamped = F_xy_clamped*jnp.cos(alpha)\n",
    "    F_y_clamped = F_xy_clamped*jnp.sin(alpha)\n",
    "    print('F_x_clamped ',F_x_clamped)\n",
    "\n",
    "    # Finally reconstruct the vector\n",
    "    # F_clamped = jnp.stack([F_x_clamped, F_y_clamped, F_z]).flatten()\n",
    "    F_clamped = jnp.ravel(jnp.column_stack([F_x_clamped, F_y_clamped, F_z]))\n",
    "    print('F_clamped   ', F_clamped)\n",
    "\n",
    "    # F_clamped = jnp.concatenate([F_x_clamped, F_y_clamped, F_z])\n",
    "    F_clamped = jnp.empty_like(F)\n",
    "    F_clamped = F_clamped.at[0::3].set(F_x_clamped)\n",
    "    F_clamped = F_clamped.at[1::3].set(F_y_clamped)\n",
    "    F_clamped = F_clamped.at[2::3].set(F_z)\n",
    "\n",
    "    print(\"F_clamped   \", F_clamped)\n",
    "\n",
    "    # --- Step 2 : Set force to zero for feet not in contact\n",
    "    F_constrained = F_clamped * c.repeat(3)\n",
    "\n",
    "    return F_constrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_horizon shape: (4, 15)\n",
      "Param horizon [[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      " [15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      " [45 46 47 48 49 50 51 52 53 54 55 56 57 58 59]]\n",
      "\n",
      "param shape: (12,)\n",
      "param values: [ 0  1  2 15 16 17 30 31 32 45 46 47]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# Example dimensions (replace with actual values)\n",
    "num_legs = 4\n",
    "time_horizon = 5\n",
    "step = 0  # Example step value\n",
    "\n",
    "# Example param_horizon array (replace with actual data)\n",
    "param_horizon = jnp.arange(num_legs * 3 * time_horizon).reshape((num_legs, 3 * time_horizon))\n",
    "\n",
    "# Extract param for a specific step\n",
    "param = param_horizon[:, 3*step:3*(step+1)].reshape(-1)\n",
    "\n",
    "print(\"param_horizon shape:\", param_horizon.shape)\n",
    "print('Param horizon', param_horizon)\n",
    "print()\n",
    "print(\"param shape:\", param.shape)\n",
    "print(\"param values:\", param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_horizon shape: (4, 15)\n",
      "Param horizon [[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      " [15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      " [45 46 47 48 49 50 51 52 53 54 55 56 57 58 59]]\n",
      "\n",
      "param shape: (12,)\n",
      "param values: [ 6  7  8 21 22 23 36 37 38 51 52 53]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "\n",
    "# Example dimensions (replace with actual values)\n",
    "num_legs = 4\n",
    "time_horizon = 5\n",
    "step = 2  # Example step value\n",
    "\n",
    "# Example param_horizon array (replace with actual data)\n",
    "param_horizon = jnp.arange(num_legs * 3 * time_horizon).reshape((num_legs, 3 * time_horizon))\n",
    "\n",
    "# Compute the index range for the slice\n",
    "start_idx = step * 3\n",
    "stop_idx = (step + 1) * 3\n",
    "\n",
    "# Use dynamic_slice to extract param for the specific step\n",
    "param_slice = lax.dynamic_slice(param_horizon, (0, start_idx), (num_legs, 3))\n",
    "\n",
    "# Reshape the sliced array into a flattened array param\n",
    "param = jnp.reshape(param_slice, (-1,))\n",
    "\n",
    "print(\"param_horizon shape:\", param_horizon.shape)\n",
    "print('Param horizon', param_horizon)\n",
    "print()\n",
    "print(\"param shape:\", param.shape)\n",
    "print(\"param values:\", param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters shape: (4, 15)\n",
      "parameters [[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      " [15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      " [45 46 47 48 49 50 51 52 53 54 55 56 57 58 59]]\n",
      "\n",
      "parameters2 shape: (4, 3, 5)\n",
      "parameters2 [[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [10 11 12 13 14]]\n",
      "\n",
      " [[15 16 17 18 19]\n",
      "  [20 21 22 23 24]\n",
      "  [25 26 27 28 29]]\n",
      "\n",
      " [[30 31 32 33 34]\n",
      "  [35 36 37 38 39]\n",
      "  [40 41 42 43 44]]\n",
      "\n",
      " [[45 46 47 48 49]\n",
      "  [50 51 52 53 54]\n",
      "  [55 56 57 58 59]]]\n",
      "\n",
      "param shape: (12,)\n",
      "param values: [ 3  4  5 18 19 20 33 34 35 48 49 50]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# Example dimensions (replace with actual values)\n",
    "num_legs = 4\n",
    "time_horizon = 5\n",
    "step = 1  # Example step value\n",
    "\n",
    "# Example param_horizon array (replace with actual data)\n",
    "parameters = jnp.arange(num_legs * 3 * time_horizon).reshape((num_legs, 3 * time_horizon))\n",
    "\n",
    "parameters2 = parameters.reshape((num_legs, 3, time_horizon))\n",
    "\n",
    "param = parameters[:, 3*step:3*(step+1)].flatten()\n",
    "\n",
    "print(\"parameters shape:\", parameters.shape)\n",
    "print('parameters', parameters)\n",
    "print()\n",
    "print(\"parameters2 shape:\", parameters2.shape)\n",
    "print('parameters2', parameters2)\n",
    "print()\n",
    "print(\"param shape:\", param.shape)\n",
    "print(\"param values:\", param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3, 5])\n",
      "tensor([[[[ 0,  1,  2,  3,  4],\n",
      "          [ 5,  6,  7,  8,  9],\n",
      "          [10, 11, 12, 13, 14]],\n",
      "\n",
      "         [[15, 16, 17, 18, 19],\n",
      "          [20, 21, 22, 23, 24],\n",
      "          [25, 26, 27, 28, 29]],\n",
      "\n",
      "         [[30, 31, 32, 33, 34],\n",
      "          [35, 36, 37, 38, 39],\n",
      "          [40, 41, 42, 43, 44]],\n",
      "\n",
      "         [[45, 46, 47, 48, 49],\n",
      "          [50, 51, 52, 53, 54],\n",
      "          [55, 56, 57, 58, 59]]]])\n",
      "\n",
      "torch.Size([1, 4, 15])\n",
      "tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "         [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
      "         [45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "F = torch.arange(60).reshape(1,4,3,5)\n",
    "print(F.shape)\n",
    "print(F)\n",
    "print()\n",
    "print(F.flatten(2,3).shape)\n",
    "print(F.flatten(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters shape: (4, 15)\n",
      "parameters [[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      " [15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      " [45 46 47 48 49 50 51 52 53 54 55 56 57 58 59]]\n",
      "\n",
      "parameters2 shape: (4, 3, 5)\n",
      "parameters2 [[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [10 11 12 13 14]]\n",
      "\n",
      " [[15 16 17 18 19]\n",
      "  [20 21 22 23 24]\n",
      "  [25 26 27 28 29]]\n",
      "\n",
      " [[30 31 32 33 34]\n",
      "  [35 36 37 38 39]\n",
      "  [40 41 42 43 44]]\n",
      "\n",
      " [[45 46 47 48 49]\n",
      "  [50 51 52 53 54]\n",
      "  [55 56 57 58 59]]]\n",
      "\n",
      "param shape: (12,)\n",
      "param values: [ 1  6 11 16 21 26 31 36 41 46 51 56]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# Example dimensions (replace with actual values)\n",
    "num_legs = 4\n",
    "time_horizon = 5\n",
    "step = 1  # Example step value\n",
    "\n",
    "# Example param_horizon array (replace with actual data)\n",
    "parameters = jnp.arange(num_legs * 3 * time_horizon).reshape((num_legs, 3 * time_horizon))\n",
    "\n",
    "parameters2 = parameters.reshape((num_legs, 3, time_horizon))\n",
    "\n",
    "\n",
    "param = parameters2[:,:,step].flatten()\n",
    "\n",
    "# param = parameters[:, 3*step:3*(step+1)].flatten()\n",
    "\n",
    "print(\"parameters shape:\", parameters.shape)\n",
    "print('parameters', parameters)\n",
    "print()\n",
    "print(\"parameters2 shape:\", parameters2.shape)\n",
    "print('parameters2', parameters2)\n",
    "print()\n",
    "print(\"param shape:\", param.shape)\n",
    "print(\"param values:\", param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ActionNormalizationCfg at 0x7f5ca1750a30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class ActionNormalizationCfg:\n",
    "    \"\"\"  Set of parameters for scaling and shifting raw action\n",
    "\n",
    "    Raw actions are distributed (initially) with mean=0 and std=1 \n",
    "    \"\"\"\n",
    "\n",
    "    # Frequency f : mean=(std_n+std_p)/2, std=(std_p-std_n)/2     : clipped to (min, max)\n",
    "    std_p_f = 1.7        # [Hz]\n",
    "    std_n_f = 1.3        # [Hz]\n",
    "    max_f = 3            # [Hz]\n",
    "    min_f = 0            # [Hz]\n",
    "\n",
    "    # Duty Cycle d : mean=(std_n+std_p)/2, std=(std_p-std_n)/2     : clipped to (min, max)\n",
    "    std_p_d = 0.63       # [2pi Rad]\n",
    "    std_n_d = 0.57       # [2pi Rad]\n",
    "    max_d = 1.0          # [2pi Rad]\n",
    "    min_d = 0.0          # [2pi Rad]\n",
    "\n",
    "    # Foot touch down position : mean=(std_n+std_p)/2, std=(std_p-std_n)/2     : clipped to (min, max)\n",
    "    std_p_x_p = +0.03    # [m]\n",
    "    std_n_x_p = -0.01    # [m] \n",
    "    std_p_y_p = +0.01    # [m]\n",
    "    std_n_y_p = -0.01    # [m]\n",
    "    max_p_x_p = +0.36    # [m]\n",
    "    min_p_x_p = -0.24    # [m]\n",
    "    max_p_y_p = +0.20    # [m]\n",
    "    min_p_y_p = -0.20    # [m]\n",
    "\n",
    "    # Ground Reaction Forces : clipped to (min, max), not clipped if set to None\n",
    "    mean_xy_F = 0        # [N]\n",
    "    std_xy_F = (10 / 2)  # [N]\n",
    "    max_xy_F = None      # [N]\n",
    "    min_xy_F = None      # [N]\n",
    "\n",
    "    mean_z_F = (200 / 2) # [N] : 200/2 ~= 20[kg_aliengo] * 9.81 [m/s] / 2 [leg in contact]\n",
    "    std_z = mean_z_F/5   # [N]\n",
    "    max_z_F = None       # [N]\n",
    "    min_z_F = 0          # [N]\n",
    "\n",
    "\n",
    "actionNormalizationCfg = ActionNormalizationCfg()\n",
    "\n",
    "actionNormalizationCfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from collections.abc import Callable, Sequence\n",
    "import inspect\n",
    "\n",
    "def callable_to_string(value: Callable) -> str:\n",
    "    \"\"\"Converts a callable object to a string.\n",
    "\n",
    "    Args:\n",
    "        value: A callable object.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: When the input argument is not a callable object.\n",
    "\n",
    "    Returns:\n",
    "        A string representation of the callable object.\n",
    "    \"\"\"\n",
    "    # check if callable\n",
    "    if not callable(value):\n",
    "        raise ValueError(f\"The input argument is not callable: {value}.\")\n",
    "    # check if lambda function\n",
    "    if value.__name__ == \"<lambda>\":\n",
    "        return f\"lambda {inspect.getsourcelines(value)[0][0].strip().split('lambda')[1].strip().split(',')[0]}\"\n",
    "    else:\n",
    "        # get the module and function name\n",
    "        module_name = value.__module__\n",
    "        function_name = value.__name__\n",
    "        # return the string\n",
    "        return f\"{module_name}:{function_name}\"\n",
    "\n",
    "def class_to_dict(obj: object) -> dict[str, Any]:\n",
    "    \"\"\"Convert an object into dictionary recursively.\n",
    "\n",
    "    Note:\n",
    "        Ignores all names starting with \"__\" (i.e. built-in methods).\n",
    "\n",
    "    Args:\n",
    "        obj: An instance of a class to convert.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: When input argument is not an object.\n",
    "\n",
    "    Returns:\n",
    "        Converted dictionary mapping.\n",
    "    \"\"\"\n",
    "    # check that input data is class instance\n",
    "    if not hasattr(obj, \"__class__\"):\n",
    "        raise ValueError(f\"Expected a class instance. Received: {type(obj)}.\")\n",
    "    # convert object to dictionary\n",
    "    if isinstance(obj, dict):\n",
    "        obj_dict = obj\n",
    "    else:\n",
    "        obj_dict = obj.__dict__\n",
    "    # convert to dictionary\n",
    "    data = dict()\n",
    "    for key, value in obj_dict.items():\n",
    "        # disregard builtin attributes\n",
    "        if key.startswith(\"__\"):\n",
    "            continue\n",
    "        # check if attribute is callable -- function\n",
    "        if callable(value):\n",
    "            data[key] = callable_to_string(value)\n",
    "        # check if attribute is a dictionary\n",
    "        elif hasattr(value, \"__dict__\") or isinstance(value, dict):\n",
    "            data[key] = class_to_dict(value)\n",
    "        else:\n",
    "            data[key] = value\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(actionNormalizationCfg.mean_z_F)\n",
    "print(class_to_dict(actionNormalizationCfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "b = torch.tensor([[1,2],[3,4]])\n",
    "# a=b\n",
    "\n",
    "a = torch.empty((2,3))\n",
    "a[:,:2] = b\n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "a[:,2] = torch.tensor([3,4])\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x749ce38bb3d0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "x = np.linspace(-7,7,100)\n",
    "\n",
    "y1 = x % (2*math.pi)\n",
    "y2 = ((x - math.pi) % (2*math.pi)) - math.pi\n",
    "plt.plot(x,y1)\n",
    "plt.plot(x,y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27],\n",
       "        [ 28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55],\n",
       "        [ 56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83],\n",
       "        [ 84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111],\n",
       "        [112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139],\n",
       "        [140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167],\n",
       "        [168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195],\n",
       "        [196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223],\n",
       "        [224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
       "         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251],\n",
       "        [252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
       "         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279],\n",
       "        [280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
       "         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307],\n",
       "        [308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
       "         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335],\n",
       "        [336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
       "         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363],\n",
       "        [364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391],\n",
       "        [392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
       "         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.arange(840).view(2,15,28)\n",
    "a[0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27],\n",
      "        [420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447]]), tensor([[ 28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55],\n",
      "        [448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "         462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475]]), tensor([[ 56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83],\n",
      "        [476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "         490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503]]), tensor([[ 84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111],\n",
      "        [504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n",
      "         518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531]]), tensor([[112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139],\n",
      "        [532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "         546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559]]), tensor([[140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167],\n",
      "        [560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,\n",
      "         574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587]]), tensor([[168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195],\n",
      "        [588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n",
      "         602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615]]), tensor([[196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223],\n",
      "        [616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629,\n",
      "         630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643]]), tensor([[224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251],\n",
      "        [644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n",
      "         658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671]]), tensor([[252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279],\n",
      "        [672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n",
      "         686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699]]), tensor([[280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307],\n",
      "        [700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713,\n",
      "         714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727]]), tensor([[308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335],\n",
      "        [728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741,\n",
      "         742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755]]), tensor([[336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363],\n",
      "        [756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769,\n",
      "         770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783]]), tensor([[364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391],\n",
      "        [784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797,\n",
      "         798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811]]), tensor([[392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419],\n",
      "        [812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825,\n",
      "         826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839]])]\n"
     ]
    }
   ],
   "source": [
    "a_list = []\n",
    "\n",
    "for i in range(15):\n",
    "    a_list.append(a[:,i,:])\n",
    "\n",
    "print(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_actions = torch.stack(a_list).permute(1,0,2)\n",
    "(raw_actions == a).all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_len, d_len, p_len, F_len= 4,4,8,12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = raw_actions[:,0,  0                 : f_len                   ]             # shape (batch_size, f_len)\n",
    "d = raw_actions[:,0,  f_len             :(f_len+d_len)            ]             # shape (batch_size, d_len)\n",
    "p = raw_actions[:,:, (f_len+d_len)      :(f_len+d_len+p_len)      ].transpose(1,2).flatten(1,2)# shape (batch_size, buffer_size*p_len)\n",
    "F = raw_actions[:,:, (f_len+d_len+p_len):(f_len+d_len+p_len+F_len)].transpose(1,2).flatten(1,2)# shape (batch_size, buffer_size*F_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3],\n",
       "        [420, 421, 422, 423]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4,   5,   6,   7],\n",
       "        [424, 425, 426, 427]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  8,  36],\n",
       "          [ 64,  92],\n",
       "          [120, 148],\n",
       "          [176, 204]],\n",
       "\n",
       "         [[232, 260],\n",
       "          [288, 316],\n",
       "          [344, 372],\n",
       "          [400,   9]],\n",
       "\n",
       "         [[ 37,  65],\n",
       "          [ 93, 121],\n",
       "          [149, 177],\n",
       "          [205, 233]],\n",
       "\n",
       "         [[261, 289],\n",
       "          [317, 345],\n",
       "          [373, 401],\n",
       "          [ 10,  38]],\n",
       "\n",
       "         [[ 66,  94],\n",
       "          [122, 150],\n",
       "          [178, 206],\n",
       "          [234, 262]],\n",
       "\n",
       "         [[290, 318],\n",
       "          [346, 374],\n",
       "          [402,  11],\n",
       "          [ 39,  67]],\n",
       "\n",
       "         [[ 95, 123],\n",
       "          [151, 179],\n",
       "          [207, 235],\n",
       "          [263, 291]],\n",
       "\n",
       "         [[319, 347],\n",
       "          [375, 403],\n",
       "          [ 12,  40],\n",
       "          [ 68,  96]],\n",
       "\n",
       "         [[124, 152],\n",
       "          [180, 208],\n",
       "          [236, 264],\n",
       "          [292, 320]],\n",
       "\n",
       "         [[348, 376],\n",
       "          [404,  13],\n",
       "          [ 41,  69],\n",
       "          [ 97, 125]],\n",
       "\n",
       "         [[153, 181],\n",
       "          [209, 237],\n",
       "          [265, 293],\n",
       "          [321, 349]],\n",
       "\n",
       "         [[377, 405],\n",
       "          [ 14,  42],\n",
       "          [ 70,  98],\n",
       "          [126, 154]],\n",
       "\n",
       "         [[182, 210],\n",
       "          [238, 266],\n",
       "          [294, 322],\n",
       "          [350, 378]],\n",
       "\n",
       "         [[406,  15],\n",
       "          [ 43,  71],\n",
       "          [ 99, 127],\n",
       "          [155, 183]],\n",
       "\n",
       "         [[211, 239],\n",
       "          [267, 295],\n",
       "          [323, 351],\n",
       "          [379, 407]]],\n",
       "\n",
       "\n",
       "        [[[428, 456],\n",
       "          [484, 512],\n",
       "          [540, 568],\n",
       "          [596, 624]],\n",
       "\n",
       "         [[652, 680],\n",
       "          [708, 736],\n",
       "          [764, 792],\n",
       "          [820, 429]],\n",
       "\n",
       "         [[457, 485],\n",
       "          [513, 541],\n",
       "          [569, 597],\n",
       "          [625, 653]],\n",
       "\n",
       "         [[681, 709],\n",
       "          [737, 765],\n",
       "          [793, 821],\n",
       "          [430, 458]],\n",
       "\n",
       "         [[486, 514],\n",
       "          [542, 570],\n",
       "          [598, 626],\n",
       "          [654, 682]],\n",
       "\n",
       "         [[710, 738],\n",
       "          [766, 794],\n",
       "          [822, 431],\n",
       "          [459, 487]],\n",
       "\n",
       "         [[515, 543],\n",
       "          [571, 599],\n",
       "          [627, 655],\n",
       "          [683, 711]],\n",
       "\n",
       "         [[739, 767],\n",
       "          [795, 823],\n",
       "          [432, 460],\n",
       "          [488, 516]],\n",
       "\n",
       "         [[544, 572],\n",
       "          [600, 628],\n",
       "          [656, 684],\n",
       "          [712, 740]],\n",
       "\n",
       "         [[768, 796],\n",
       "          [824, 433],\n",
       "          [461, 489],\n",
       "          [517, 545]],\n",
       "\n",
       "         [[573, 601],\n",
       "          [629, 657],\n",
       "          [685, 713],\n",
       "          [741, 769]],\n",
       "\n",
       "         [[797, 825],\n",
       "          [434, 462],\n",
       "          [490, 518],\n",
       "          [546, 574]],\n",
       "\n",
       "         [[602, 630],\n",
       "          [658, 686],\n",
       "          [714, 742],\n",
       "          [770, 798]],\n",
       "\n",
       "         [[826, 435],\n",
       "          [463, 491],\n",
       "          [519, 547],\n",
       "          [575, 603]],\n",
       "\n",
       "         [[631, 659],\n",
       "          [687, 715],\n",
       "          [743, 771],\n",
       "          [799, 827]]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.view(2,15,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 16,  44,  72, 100, 128, 156, 184, 212, 240, 268, 296, 324, 352, 380,\n",
       "         408,  17,  45,  73, 101, 129, 157, 185, 213, 241, 269, 297, 325, 353,\n",
       "         381, 409,  18,  46,  74, 102, 130, 158, 186, 214, 242, 270, 298, 326,\n",
       "         354, 382, 410,  19,  47,  75, 103, 131, 159, 187, 215, 243, 271, 299,\n",
       "         327, 355, 383, 411,  20,  48,  76, 104, 132, 160, 188, 216, 244, 272,\n",
       "         300, 328, 356, 384, 412,  21,  49,  77, 105, 133, 161, 189, 217, 245,\n",
       "         273, 301, 329, 357, 385, 413,  22,  50,  78, 106, 134, 162, 190, 218,\n",
       "         246, 274, 302, 330, 358, 386, 414,  23,  51,  79, 107, 135, 163, 191,\n",
       "         219, 247, 275, 303, 331, 359, 387, 415,  24,  52,  80, 108, 136, 164,\n",
       "         192, 220, 248, 276, 304, 332, 360, 388, 416,  25,  53,  81, 109, 137,\n",
       "         165, 193, 221, 249, 277, 305, 333, 361, 389, 417,  26,  54,  82, 110,\n",
       "         138, 166, 194, 222, 250, 278, 306, 334, 362, 390, 418,  27,  55,  83,\n",
       "         111, 139, 167, 195, 223, 251, 279, 307, 335, 363, 391, 419],\n",
       "        [436, 464, 492, 520, 548, 576, 604, 632, 660, 688, 716, 744, 772, 800,\n",
       "         828, 437, 465, 493, 521, 549, 577, 605, 633, 661, 689, 717, 745, 773,\n",
       "         801, 829, 438, 466, 494, 522, 550, 578, 606, 634, 662, 690, 718, 746,\n",
       "         774, 802, 830, 439, 467, 495, 523, 551, 579, 607, 635, 663, 691, 719,\n",
       "         747, 775, 803, 831, 440, 468, 496, 524, 552, 580, 608, 636, 664, 692,\n",
       "         720, 748, 776, 804, 832, 441, 469, 497, 525, 553, 581, 609, 637, 665,\n",
       "         693, 721, 749, 777, 805, 833, 442, 470, 498, 526, 554, 582, 610, 638,\n",
       "         666, 694, 722, 750, 778, 806, 834, 443, 471, 499, 527, 555, 583, 611,\n",
       "         639, 667, 695, 723, 751, 779, 807, 835, 444, 472, 500, 528, 556, 584,\n",
       "         612, 640, 668, 696, 724, 752, 780, 808, 836, 445, 473, 501, 529, 557,\n",
       "         585, 613, 641, 669, 697, 725, 753, 781, 809, 837, 446, 474, 502, 530,\n",
       "         558, 586, 614, 642, 670, 698, 726, 754, 782, 810, 838, 447, 475, 503,\n",
       "         531, 559, 587, 615, 643, 671, 699, 727, 755, 783, 811, 839]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,  36,  64,  92, 120, 148,\n",
       "         176, 204, 232, 260, 288, 316, 344, 372, 400,   9,  37,  65,  93, 121,\n",
       "         149, 177, 205, 233, 261, 289, 317, 345, 373, 401,  10,  38,  66,  94,\n",
       "         122, 150, 178, 206, 234, 262, 290, 318, 346, 374, 402,  11,  39,  67,\n",
       "          95, 123, 151, 179, 207, 235, 263, 291, 319, 347, 375, 403,  12,  40,\n",
       "          68,  96, 124, 152, 180, 208, 236, 264, 292, 320, 348, 376, 404,  13,\n",
       "          41,  69,  97, 125, 153, 181, 209, 237, 265, 293, 321, 349, 377, 405,\n",
       "          14,  42,  70,  98, 126, 154, 182, 210, 238, 266, 294, 322, 350, 378,\n",
       "         406,  15,  43,  71,  99, 127, 155, 183, 211, 239, 267, 295, 323, 351,\n",
       "         379, 407,  16,  44,  72, 100, 128, 156, 184, 212, 240, 268, 296, 324,\n",
       "         352, 380, 408,  17,  45,  73, 101, 129, 157, 185, 213, 241, 269, 297,\n",
       "         325, 353, 381, 409,  18,  46,  74, 102, 130, 158, 186, 214, 242, 270,\n",
       "         298, 326, 354, 382, 410,  19,  47,  75, 103, 131, 159, 187, 215, 243,\n",
       "         271, 299, 327, 355, 383, 411,  20,  48,  76, 104, 132, 160, 188, 216,\n",
       "         244, 272, 300, 328, 356, 384, 412,  21,  49,  77, 105, 133, 161, 189,\n",
       "         217, 245, 273, 301, 329, 357, 385, 413,  22,  50,  78, 106, 134, 162,\n",
       "         190, 218, 246, 274, 302, 330, 358, 386, 414,  23,  51,  79, 107, 135,\n",
       "         163, 191, 219, 247, 275, 303, 331, 359, 387, 415,  24,  52,  80, 108,\n",
       "         136, 164, 192, 220, 248, 276, 304, 332, 360, 388, 416,  25,  53,  81,\n",
       "         109, 137, 165, 193, 221, 249, 277, 305, 333, 361, 389, 417,  26,  54,\n",
       "          82, 110, 138, 166, 194, 222, 250, 278, 306, 334, 362, 390, 418,  27,\n",
       "          55,  83, 111, 139, 167, 195, 223, 251, 279, 307, 335, 363, 391, 419],\n",
       "        [420, 421, 422, 423, 424, 425, 426, 427, 428, 456, 484, 512, 540, 568,\n",
       "         596, 624, 652, 680, 708, 736, 764, 792, 820, 429, 457, 485, 513, 541,\n",
       "         569, 597, 625, 653, 681, 709, 737, 765, 793, 821, 430, 458, 486, 514,\n",
       "         542, 570, 598, 626, 654, 682, 710, 738, 766, 794, 822, 431, 459, 487,\n",
       "         515, 543, 571, 599, 627, 655, 683, 711, 739, 767, 795, 823, 432, 460,\n",
       "         488, 516, 544, 572, 600, 628, 656, 684, 712, 740, 768, 796, 824, 433,\n",
       "         461, 489, 517, 545, 573, 601, 629, 657, 685, 713, 741, 769, 797, 825,\n",
       "         434, 462, 490, 518, 546, 574, 602, 630, 658, 686, 714, 742, 770, 798,\n",
       "         826, 435, 463, 491, 519, 547, 575, 603, 631, 659, 687, 715, 743, 771,\n",
       "         799, 827, 436, 464, 492, 520, 548, 576, 604, 632, 660, 688, 716, 744,\n",
       "         772, 800, 828, 437, 465, 493, 521, 549, 577, 605, 633, 661, 689, 717,\n",
       "         745, 773, 801, 829, 438, 466, 494, 522, 550, 578, 606, 634, 662, 690,\n",
       "         718, 746, 774, 802, 830, 439, 467, 495, 523, 551, 579, 607, 635, 663,\n",
       "         691, 719, 747, 775, 803, 831, 440, 468, 496, 524, 552, 580, 608, 636,\n",
       "         664, 692, 720, 748, 776, 804, 832, 441, 469, 497, 525, 553, 581, 609,\n",
       "         637, 665, 693, 721, 749, 777, 805, 833, 442, 470, 498, 526, 554, 582,\n",
       "         610, 638, 666, 694, 722, 750, 778, 806, 834, 443, 471, 499, 527, 555,\n",
       "         583, 611, 639, 667, 695, 723, 751, 779, 807, 835, 444, 472, 500, 528,\n",
       "         556, 584, 612, 640, 668, 696, 724, 752, 780, 808, 836, 445, 473, 501,\n",
       "         529, 557, 585, 613, 641, 669, 697, 725, 753, 781, 809, 837, 446, 474,\n",
       "         502, 530, 558, 586, 614, 642, 670, 698, 726, 754, 782, 810, 838, 447,\n",
       "         475, 503, 531, 559, 587, 615, 643, 671, 699, 727, 755, 783, 811, 839]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_to_store = torch.cat((f,d,p,F),dim=1) \n",
    "action_to_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_envs=2\n",
    "_num_legs=4\n",
    "_p_param=15\n",
    "_F_param=15\n",
    "f_raw  = 1.0*torch.ones(num_envs, _num_legs,             ) \n",
    "d_raw  = 0.6*torch.ones( num_envs, _num_legs,            )\n",
    "p_raw  =     torch.zeros(num_envs, _num_legs, 2, _p_param)\n",
    "F_raw  =     torch.zeros(num_envs, _num_legs, 3, _F_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "120\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "f_len = f_raw.shape[1:].numel()\n",
    "d_len = d_raw.shape[1:].numel()\n",
    "p_len = p_raw.shape[1:].numel()\n",
    "F_len = F_raw.shape[1:].numel()\n",
    "print(f_len)\n",
    "print(d_len)\n",
    "print(p_len)\n",
    "print(F_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_raw = (action_to_store[:, 0                     : f_len                        ]).reshape_as(f_raw)\n",
    "d_raw = (action_to_store[:, f_len                 : f_len + d_len                ]).reshape_as(d_raw)\n",
    "p_raw = (action_to_store[:, f_len + d_len         : f_len + d_len + p_len        ]).reshape_as(p_raw)\n",
    "F_raw = (action_to_store[:, f_len + d_len + p_len : f_len + d_len + p_len + F_len]).reshape_as(F_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3],\n",
       "        [420, 421, 422, 423]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4,   5,   6,   7],\n",
       "        [424, 425, 426, 427]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  8,  36,  64,  92, 120, 148, 176, 204, 232, 260, 288, 316, 344, 372,\n",
       "           400],\n",
       "          [  9,  37,  65,  93, 121, 149, 177, 205, 233, 261, 289, 317, 345, 373,\n",
       "           401]],\n",
       "\n",
       "         [[ 10,  38,  66,  94, 122, 150, 178, 206, 234, 262, 290, 318, 346, 374,\n",
       "           402],\n",
       "          [ 11,  39,  67,  95, 123, 151, 179, 207, 235, 263, 291, 319, 347, 375,\n",
       "           403]],\n",
       "\n",
       "         [[ 12,  40,  68,  96, 124, 152, 180, 208, 236, 264, 292, 320, 348, 376,\n",
       "           404],\n",
       "          [ 13,  41,  69,  97, 125, 153, 181, 209, 237, 265, 293, 321, 349, 377,\n",
       "           405]],\n",
       "\n",
       "         [[ 14,  42,  70,  98, 126, 154, 182, 210, 238, 266, 294, 322, 350, 378,\n",
       "           406],\n",
       "          [ 15,  43,  71,  99, 127, 155, 183, 211, 239, 267, 295, 323, 351, 379,\n",
       "           407]]],\n",
       "\n",
       "\n",
       "        [[[428, 456, 484, 512, 540, 568, 596, 624, 652, 680, 708, 736, 764, 792,\n",
       "           820],\n",
       "          [429, 457, 485, 513, 541, 569, 597, 625, 653, 681, 709, 737, 765, 793,\n",
       "           821]],\n",
       "\n",
       "         [[430, 458, 486, 514, 542, 570, 598, 626, 654, 682, 710, 738, 766, 794,\n",
       "           822],\n",
       "          [431, 459, 487, 515, 543, 571, 599, 627, 655, 683, 711, 739, 767, 795,\n",
       "           823]],\n",
       "\n",
       "         [[432, 460, 488, 516, 544, 572, 600, 628, 656, 684, 712, 740, 768, 796,\n",
       "           824],\n",
       "          [433, 461, 489, 517, 545, 573, 601, 629, 657, 685, 713, 741, 769, 797,\n",
       "           825]],\n",
       "\n",
       "         [[434, 462, 490, 518, 546, 574, 602, 630, 658, 686, 714, 742, 770, 798,\n",
       "           826],\n",
       "          [435, 463, 491, 519, 547, 575, 603, 631, 659, 687, 715, 743, 771, 799,\n",
       "           827]]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 16,  44,  72, 100, 128, 156, 184, 212, 240, 268, 296, 324, 352, 380,\n",
       "           408],\n",
       "          [ 17,  45,  73, 101, 129, 157, 185, 213, 241, 269, 297, 325, 353, 381,\n",
       "           409],\n",
       "          [ 18,  46,  74, 102, 130, 158, 186, 214, 242, 270, 298, 326, 354, 382,\n",
       "           410]],\n",
       "\n",
       "         [[ 19,  47,  75, 103, 131, 159, 187, 215, 243, 271, 299, 327, 355, 383,\n",
       "           411],\n",
       "          [ 20,  48,  76, 104, 132, 160, 188, 216, 244, 272, 300, 328, 356, 384,\n",
       "           412],\n",
       "          [ 21,  49,  77, 105, 133, 161, 189, 217, 245, 273, 301, 329, 357, 385,\n",
       "           413]],\n",
       "\n",
       "         [[ 22,  50,  78, 106, 134, 162, 190, 218, 246, 274, 302, 330, 358, 386,\n",
       "           414],\n",
       "          [ 23,  51,  79, 107, 135, 163, 191, 219, 247, 275, 303, 331, 359, 387,\n",
       "           415],\n",
       "          [ 24,  52,  80, 108, 136, 164, 192, 220, 248, 276, 304, 332, 360, 388,\n",
       "           416]],\n",
       "\n",
       "         [[ 25,  53,  81, 109, 137, 165, 193, 221, 249, 277, 305, 333, 361, 389,\n",
       "           417],\n",
       "          [ 26,  54,  82, 110, 138, 166, 194, 222, 250, 278, 306, 334, 362, 390,\n",
       "           418],\n",
       "          [ 27,  55,  83, 111, 139, 167, 195, 223, 251, 279, 307, 335, 363, 391,\n",
       "           419]]],\n",
       "\n",
       "\n",
       "        [[[436, 464, 492, 520, 548, 576, 604, 632, 660, 688, 716, 744, 772, 800,\n",
       "           828],\n",
       "          [437, 465, 493, 521, 549, 577, 605, 633, 661, 689, 717, 745, 773, 801,\n",
       "           829],\n",
       "          [438, 466, 494, 522, 550, 578, 606, 634, 662, 690, 718, 746, 774, 802,\n",
       "           830]],\n",
       "\n",
       "         [[439, 467, 495, 523, 551, 579, 607, 635, 663, 691, 719, 747, 775, 803,\n",
       "           831],\n",
       "          [440, 468, 496, 524, 552, 580, 608, 636, 664, 692, 720, 748, 776, 804,\n",
       "           832],\n",
       "          [441, 469, 497, 525, 553, 581, 609, 637, 665, 693, 721, 749, 777, 805,\n",
       "           833]],\n",
       "\n",
       "         [[442, 470, 498, 526, 554, 582, 610, 638, 666, 694, 722, 750, 778, 806,\n",
       "           834],\n",
       "          [443, 471, 499, 527, 555, 583, 611, 639, 667, 695, 723, 751, 779, 807,\n",
       "           835],\n",
       "          [444, 472, 500, 528, 556, 584, 612, 640, 668, 696, 724, 752, 780, 808,\n",
       "           836]],\n",
       "\n",
       "         [[445, 473, 501, 529, 557, 585, 613, 641, 669, 697, 725, 753, 781, 809,\n",
       "           837],\n",
       "          [446, 474, 502, 530, 558, 586, 614, 642, 670, 698, 726, 754, 782, 810,\n",
       "           838],\n",
       "          [447, 475, 503, 531, 559, 587, 615, 643, 671, 699, 727, 755, 783, 811,\n",
       "           839]]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28])\n"
     ]
    }
   ],
   "source": [
    "num_envs=1\n",
    "_num_legs=4\n",
    "_p_param=1\n",
    "_F_param=1\n",
    "\n",
    "f_raw  = 1.0*torch.ones(num_envs, _num_legs,             ) \n",
    "d_raw  = 0.6*torch.ones( num_envs, _num_legs,            )\n",
    "p_raw  =     torch.zeros(num_envs, _num_legs, 2, _p_param)\n",
    "F_raw  =     torch.zeros(num_envs, _num_legs, 3, _F_param)\n",
    "\n",
    "\n",
    "b = torch.arange(28).unsqueeze(0)\n",
    "print(b.shape)\n",
    "f_len, d_len, p_len, F_len = 4, 4, 8, 12\n",
    "\n",
    "f_raw = (b[:, 0                     : f_len                        ]).reshape_as(f_raw)\n",
    "d_raw = (b[:, f_len                 : f_len + d_len                ]).reshape_as(d_raw)\n",
    "p_raw = (b[:, f_len + d_len         : f_len + d_len + p_len        ]).reshape_as(p_raw)\n",
    "F_raw = (b[:, f_len + d_len + p_len : f_len + d_len + p_len + F_len]).reshape_as(F_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3]])\n",
      "tensor([[4, 5, 6, 7]])\n",
      "tensor([[[[ 8],\n",
      "          [ 9]],\n",
      "\n",
      "         [[10],\n",
      "          [11]],\n",
      "\n",
      "         [[12],\n",
      "          [13]],\n",
      "\n",
      "         [[14],\n",
      "          [15]]]])\n",
      "tensor([[[[16],\n",
      "          [17],\n",
      "          [18]],\n",
      "\n",
      "         [[19],\n",
      "          [20],\n",
      "          [21]],\n",
      "\n",
      "         [[22],\n",
      "          [23],\n",
      "          [24]],\n",
      "\n",
      "         [[25],\n",
      "          [26],\n",
      "          [27]]]])\n"
     ]
    }
   ],
   "source": [
    "print(f_raw)\n",
    "print(d_raw)\n",
    "print(p_raw)\n",
    "print(F_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting variable Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "\n",
    "class ModelBaseAction():\n",
    "    def __init__(self, num_envs, num_legs, device, time_horizon):\n",
    "        self. num_envs = num_envs\n",
    "        self._num_legs = num_legs\n",
    "        self.device=device\n",
    "        self._p_param = time_horizon\n",
    "        self._F_param = time_horizon\n",
    "\n",
    "        # raw RL output\n",
    "        self.f_raw  = 1.0*torch.ones( self.num_envs, self._num_legs,                   device=self.device) \n",
    "        self.d_raw  = 0.6*torch.ones( self.num_envs, self._num_legs,                   device=self.device)\n",
    "        self.p_raw  =     torch.zeros(self.num_envs, self._num_legs, 2, self._p_param, device=self.device)\n",
    "        self.F_raw  =     torch.zeros(self.num_envs, self._num_legs, 3, self._F_param, device=self.device)\n",
    "\n",
    "        # For ease of reshaping variables\n",
    "        self.f_len = self.f_raw.shape[1:].numel()\n",
    "        self.d_len = self.d_raw.shape[1:].numel()\n",
    "        self.p_len = self.p_raw.shape[1:].numel()\n",
    "        self.F_len = self.F_raw.shape[1:].numel()\n",
    "\n",
    "        # create tensors for raw and processed actions\n",
    "        self._raw_actions = torch.zeros(self.num_envs, self.action_dim, device=self.device)\n",
    "\n",
    "    @property\n",
    "    def action_dim(self) -> int:\n",
    "        return self.f_len + self.d_len  + self.p_len + self.F_len \n",
    "\n",
    "    def process_actions(self, actions: torch.Tensor):\n",
    "        # store the raw actions\n",
    "        self._raw_actions[:] = actions\n",
    "\n",
    "\n",
    "        # reconstruct the latent variable from the RL poliy actions\n",
    "        self.f_raw = (self._raw_actions[:, 0                                    : self.f_len                                       ]).reshape_as(self.f_raw)\n",
    "        self.d_raw = (self._raw_actions[:, self.f_len                           : self.f_len + self.d_len                          ]).reshape_as(self.d_raw)\n",
    "        self.p_raw = (self._raw_actions[:, self.f_len + self.d_len              : self.f_len + self.d_len + self.p_len             ]).reshape_as(self.p_raw)\n",
    "        self.F_raw = (self._raw_actions[:, self.f_len + self.d_len + self.p_len : self.f_len + self.d_len + self.p_len + self.F_len]).reshape_as(self.F_raw)\n",
    "\n",
    "\n",
    "class DataLogger():\n",
    "    def __init__(self):\n",
    "        f_len, d_len, p_len, F_len = 4, 4, 8, 12\n",
    "        pass\n",
    "\n",
    "    def encode_actions(self, buffer_act:list):\n",
    "        f_len, d_len, p_len, F_len = 4, 4, 8, 12\n",
    "\n",
    "        raw_actions = torch.stack(buffer_act).permute(1,2,0)                            # shape (batch_size, act_dim, buffer_size)\n",
    "        f = raw_actions[:, 0                 : f_len                   , 0]             # shape (batch_size, f_len)\n",
    "        d = raw_actions[:, f_len             :(f_len+d_len)            , 0]             # shape (batch_size, d_len)\n",
    "        p = raw_actions[:,(f_len+d_len)      :(f_len+d_len+p_len)      , :].flatten(1,2)# shape (batch_size, buffer_size*p_len) /!\\ Transpose to store the data with the right format\n",
    "        F = raw_actions[:,(f_len+d_len+p_len):(f_len+d_len+p_len+F_len), :].flatten(1,2)# shape (batch_size, buffer_size*F_len)\n",
    "        action_to_store = torch.cat((f,d,p,F),dim=1)                                    # shape (batch_size, f_len+d_len+buffer_size*(p_len+F_len))\n",
    "        \n",
    "        return action_to_store\n",
    "        \n",
    "\n",
    "num_envs = 5\n",
    "num_legs = 4\n",
    "device = 'cpu'\n",
    "time_horizon = 15\n",
    "\n",
    "action_list = []\n",
    "\n",
    "for i in range(time_horizon):\n",
    "    action_list.append(torch.randn((num_envs, 28),device=device))\n",
    "\n",
    "# print(action_list)\n",
    "\n",
    "dataLogger = DataLogger()\n",
    "modelBaseAction = ModelBaseAction(num_envs=num_envs, num_legs=num_legs, device=device, time_horizon=time_horizon)\n",
    "\n",
    "encoded_actions = dataLogger.encode_actions(buffer_act=action_list)\n",
    "\n",
    "modelBaseAction.process_actions(actions=encoded_actions)\n",
    "\n",
    "assert ( modelBaseAction.f_raw == action_list[0][:, 0:4] ).all() , 'f don\\'t match'\n",
    "assert ( modelBaseAction.d_raw == action_list[0][:, 4:8] ).all() , 'd don\\'t match'\n",
    "\n",
    "for i in range(time_horizon):\n",
    "    assert ( modelBaseAction.p_raw[:,:,:,i].reshape(num_envs, 8) == action_list[i][:,  8:16] ).all() , f\"p {i} don\\'t match\"\n",
    "    assert ( modelBaseAction.F_raw[:,:,:,i].reshape(num_envs,12) == action_list[i][:, 16:28] ).all() , f\"F {i} don\\'t match\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orbit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
